version: '3.8'

services:
  db:
    image: postgres:15-alpine
    container_name: expense_bot_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=${DB_NAME:-expense_bot}
      - POSTGRES_USER=${DB_USER:-expense_user}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-expense_password}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-expense_user} -d ${DB_NAME:-expense_bot}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  redis:
    image: redis:7-alpine
    container_name: expense_bot_redis
    command: redis-server --requirepass ${REDIS_PASSWORD:-redis_password}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s

  bot:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: expense_bot_app
    dns:
      - 8.8.8.8
      - 1.1.1.1
    env_file:
      - .env
    environment:
      - DB_HOST=db
      - DB_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DJANGO_SETTINGS_MODULE=expense_bot.settings
    volumes:
      - ./logs:/app/logs
      - ./media:/app/media
      - ./staticfiles:/app/staticfiles
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: python -m bot.main
    ports:
      - "127.0.0.1:8001:8000"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  celery:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: expense_bot_celery
    dns:
      - 8.8.8.8
      - 1.1.1.1
    env_file:
      - .env
    environment:
      - DB_HOST=db
      - DB_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DJANGO_SETTINGS_MODULE=expense_bot.settings
    volumes:
      - ./logs:/app/logs
      - ./media:/app/media
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: celery -A expense_bot worker --loglevel=info -Q default,reports,recurring,maintenance,notifications,monitoring,analytics
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: expense_bot_celery_beat
    dns:
      - 8.8.8.8
      - 1.1.1.1
    env_file:
      - .env
    environment:
      - DB_HOST=db
      - DB_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DJANGO_SETTINGS_MODULE=expense_bot.settings
    volumes:
      - ./logs:/app/logs
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: celery -A expense_bot beat --loglevel=info
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

  # Optional: Django admin panel
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: expense_bot_web
    dns:
      - 8.8.8.8
      - 1.1.1.1
    env_file:
      - .env
    environment:
      - DB_HOST=db
      - DB_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DJANGO_SETTINGS_MODULE=expense_bot.settings
    volumes:
      - ./logs:/app/logs
      - ./media:/app/media
      - ./staticfiles:/app/staticfiles
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    command: gunicorn expense_bot.wsgi:application --bind 0.0.0.0:8000 --workers 4 --timeout 30 --graceful-timeout 30 --worker-class sync --max-requests 1000 --max-requests-jitter 50
    ports:
      - "127.0.0.1:8000:8000"
    logging:
      driver: "json-file"
      options:
        max-size: "30m"
        max-file: "3"

volumes:
  postgres_data:
