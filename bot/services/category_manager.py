"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
"""
import re
import logging
from typing import Optional, List, Set
from asgiref.sync import sync_to_async

from expenses.models import Profile, ExpenseCategory, CategoryKeyword
from bot.utils.default_categories import UNIFIED_CATEGORIES
from bot.services.ai_service import ai_service

logger = logging.getLogger(__name__)


def detect_language(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
    # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    clean_text = re.sub(r'[^\w\s\-–∞-—è–ê-–Ø—ë–Åa-zA-Z]', '', text)
    
    has_cyrillic = bool(re.search(r'[–∞-—è–ê-–Ø—ë–Å]', clean_text))
    has_latin = bool(re.search(r'[a-zA-Z]', clean_text))
    
    if has_cyrillic and not has_latin:
        return 'ru'
    elif has_latin and not has_cyrillic:
        return 'en'
    else:
        return 'mixed'


def extract_emoji(text: str) -> Optional[str]:
    """–ò–∑–≤–ª–µ—á—å —ç–º–æ–¥–∑–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags
        "\U00002702-\U000027B0"
        "\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE
    )
    emojis = emoji_pattern.findall(text)
    return emojis[0] if emojis else None


def remove_emoji(text: str) -> str:
    """–£–¥–∞–ª–∏—Ç—å —ç–º–æ–¥–∑–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"
        "\U0001F300-\U0001F5FF"
        "\U0001F680-\U0001F6FF"
        "\U0001F1E0-\U0001F1FF"
        "\U00002702-\U000027B0"
        "\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE
    )
    return emoji_pattern.sub('', text)


async def translate_with_ai(text: str, from_lang: str, to_lang: str) -> str:
    """–ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é AI"""
    try:
        from_lang_name = '—Ä—É—Å—Å–∫–æ–≥–æ' if from_lang == 'ru' else '–∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ'
        to_lang_name = '–∞–Ω–≥–ª–∏–π—Å–∫–∏–π' if to_lang == 'en' else '—Ä—É—Å—Å–∫–∏–π'
        
        prompt = f"""
        –ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤ —Å {from_lang_name} –Ω–∞ {to_lang_name}.
        –¢–µ–∫—Å—Ç: {text}
        
        –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –ø–µ—Ä–µ–≤–æ–¥ –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.
        """
        
        response = await ai_service.generate(prompt, max_tokens=50)
        return response.strip().strip('"\'')
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {e}")
        return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –µ—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è


async def generate_keywords_with_ai(category_name: str, language: str) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é AI"""
    try:
        lang_name = '—Ä—É—Å—Å–∫–æ–º' if language == 'ru' else '–∞–Ω–≥–ª–∏–π—Å–∫–æ–º'
        
        prompt = f"""
        –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤ "{category_name}" –Ω–∞ {lang_name} —è–∑—ã–∫–µ 
        —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π 5-10 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ 
        –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —ç—Ç—É –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é —Ç—Ä–∞—Ç—ã.
        
        –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "–ü—Ä–æ–¥—É–∫—Ç—ã": –º–∞–≥–∞–∑–∏–Ω, —Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç, –ø—Ä–æ–¥—É–∫—Ç—ã, –µ–¥–∞
        
        –í–µ—Ä–Ω–∏ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏.
        """
        
        response = await ai_service.generate(prompt, max_tokens=100)
        keywords = [k.strip() for k in response.split(',')]
        return keywords[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
        return []


@sync_to_async
def create_default_categories(profile_id: int):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π"""
    try:
        profile = Profile.objects.get(telegram_id=profile_id)
        
        for cat_data in UNIFIED_CATEGORIES:
            # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            category = ExpenseCategory.objects.create(
                profile=profile,
                name=f"{cat_data['icon']} {cat_data['name_ru']}",  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                name_ru=cat_data['name_ru'],
                name_en=cat_data['name_en'],
                icon=cat_data['icon'],
                original_language='mixed',  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ –æ–±–æ–∏—Ö —è–∑—ã–∫–∞—Ö
                is_translatable=True
            )
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
            for keyword in cat_data.get('keywords_ru', []):
                CategoryKeyword.objects.create(
                    category=category,
                    keyword=keyword.lower(),
                    language='ru'
                )
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
            for keyword in cat_data.get('keywords_en', []):
                CategoryKeyword.objects.create(
                    category=category,
                    keyword=keyword.lower(),
                    language='en'
                )
                
        logger.info(f"–°–æ–∑–¥–∞–Ω—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {profile_id}")
        
    except Profile.DoesNotExist:
        logger.error(f"–ü—Ä–æ—Ñ–∏–ª—å {profile_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {e}")


async def create_user_category(profile_id: int, category_name: str) -> Optional[ExpenseCategory]:
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –∞–≤—Ç–æ–ø–µ—Ä–µ–≤–æ–¥–æ–º"""
    try:
        profile = await sync_to_async(Profile.objects.get)(telegram_id=profile_id)
        user_lang = profile.language_code or 'ru'
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–æ–¥–∑–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        emoji = extract_emoji(category_name)
        text = remove_emoji(category_name).strip()
        
        if not text:
            return None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –≤–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        detected_lang = detect_language(text)
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        category = ExpenseCategory()
        category.profile = profile
        category.icon = emoji or 'üì¶'
        
        if detected_lang == user_lang or detected_lang == 'mixed':
            # –¢–µ–∫—Å—Ç –Ω–∞ —è–∑—ã–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ —Å–º–µ—à–∞–Ω–Ω—ã–π - –ø–µ—Ä–µ–≤–æ–¥–∏–º
            if user_lang == 'ru':
                category.name_ru = text
                category.name_en = await translate_with_ai(text, 'ru', 'en')
            else:
                category.name_en = text
                category.name_ru = await translate_with_ai(text, 'en', 'ru')
            
            category.original_language = user_lang
            category.is_translatable = True
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–±–æ–∏—Ö —è–∑—ã–∫–æ–≤
            keywords_ru = await generate_keywords_with_ai(category.name_ru, 'ru')
            keywords_en = await generate_keywords_with_ai(category.name_en, 'en')
            
        else:
            # –¢–µ–∫—Å—Ç –Ω–∞ –¥—Ä—É–≥–æ–º —è–∑—ã–∫–µ - –ù–ï –ø–µ—Ä–µ–≤–æ–¥–∏–º
            if detected_lang == 'ru':
                category.name_ru = text
                category.name_en = None
                category.original_language = 'ru'
            elif detected_lang == 'en':
                category.name_en = text
                category.name_ru = None
                category.original_language = 'en'
            
            category.is_translatable = False
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ —è–∑—ã–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if user_lang == 'ru':
                keywords_ru = await generate_keywords_with_ai(text, 'ru')
                keywords_en = []
            else:
                keywords_en = await generate_keywords_with_ai(text, 'en')
                keywords_ru = []
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª–µ name –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        category.name = f"{category.icon} {text}"
        
        await sync_to_async(category.save)()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in keywords_ru:
            await sync_to_async(CategoryKeyword.objects.create)(
                category=category,
                keyword=keyword.lower(),
                language='ru'
            )
        
        for keyword in keywords_en:
            await sync_to_async(CategoryKeyword.objects.create)(
                category=category,
                keyword=keyword.lower(),
                language='en'
            )
        
        logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è '{text}' –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {profile_id}")
        return category
        
    except Profile.DoesNotExist:
        logger.error(f"–ü—Ä–æ—Ñ–∏–ª—å {profile_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {e}")
        return None


def normalize_text_for_search(text: str) -> Set[str]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞"""
    # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'[^\w\s\-–∞-—è–ê-–Ø—ë–Åa-zA-Z]', ' ', text)
    text = text.lower().strip()
    
    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    tokens = re.findall(r'[\w–∞-—è–ê-–Ø—ë–Åa-zA-Z]+', text)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    stop_words = {'–∏', '–≤', '–Ω–∞', '–ø–æ', '–¥–ª—è', '—Å', '–æ—Ç', '–¥–æ', '–∏–∑', 
                  'and', 'or', 'the', 'for', 'with', 'from', 'to', 'at'}
    
    return {token for token in tokens if token and token not in stop_words}


async def find_category_by_name(profile: Profile, search_text: str) -> Optional[ExpenseCategory]:
    """–ü–æ–∏—Å–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º"""
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    search_tokens = normalize_text_for_search(search_text)
    if not search_tokens:
        return None
    
    categories = await sync_to_async(list)(
        profile.categories.filter(is_active=True)
    )
    
    best_match = None
    best_score = 0
    
    for category in categories:
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        names_to_check = []
        
        if category.name_ru:
            names_to_check.append(category.name_ru)
        if category.name_en:
            names_to_check.append(category.name_en)
        if category.name:
            names_to_check.append(category.name)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        for name in names_to_check:
            if not name:
                continue
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category_tokens = normalize_text_for_search(name)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
            common_tokens = search_tokens & category_tokens
            
            if common_tokens:
                # –í—ã—á–∏—Å–ª—è–µ–º score –∫–∞–∫ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∫ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
                score = len(common_tokens) / max(len(search_tokens), len(category_tokens))
                
                # –ë–æ–Ω—É—Å –∑–∞ –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
                if search_tokens.issubset(category_tokens) or category_tokens.issubset(search_tokens):
                    score += 0.5
                
                if score > best_score:
                    best_score = score
                    best_match = category
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –µ—Å–ª–∏ score –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∏–π
    return best_match if best_score >= 0.5 else None