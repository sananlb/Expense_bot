from celery import shared_task
from datetime import datetime, date, timedelta, time
import asyncio
import logging
import re
import os
from typing import List

from django.conf import settings
from django.db.models import Count, Sum, Avg, Case, When, FloatField, Q
from django.utils import timezone
from aiogram import Bot
from aiogram.types import InlineKeyboardMarkup
from aiogram.exceptions import TelegramBadRequest, TelegramNotFound

logger = logging.getLogger(__name__)

def _shutdown_event_loop(loop: asyncio.AbstractEventLoop, *, bot: Bot = None, label: str = "") -> None:
    """
    Deterministically shutdown a manually-created asyncio event loop.

    Celery tasks here run async code via run_until_complete(). Some libraries (e.g. aiohttp/aiogram)
    may schedule additional cleanup work that needs at least one extra loop iteration (or pending tasks
    completion) before loop.close(), otherwise you can get "Unclosed client session/connector".
    """
    if loop is None:
        return

    if getattr(loop, "is_closed", lambda: False)():
        return

    ctx = f" in {label}" if label else ""

    try:
        # Ensure this loop is the current one for any cleanup relying on get_event_loop().
        try:
            asyncio.set_event_loop(loop)
        except Exception:
            pass

        if bot is not None:
            try:
                loop.run_until_complete(bot.close())
            except Exception as e:
                logger.error(f"Failed to close bot session{ctx}: {e}", exc_info=True)

            # Extra safety: explicitly close underlying aiohttp session if exposed.
            try:
                session = getattr(bot, "session", None)
                if session is not None:
                    is_closed = getattr(session, "closed", False)
                    if not is_closed:
                        loop.run_until_complete(session.close())
            except Exception as e:
                logger.error(f"Failed to close bot aiohttp session{ctx}: {e}", exc_info=True)

        # Close all AI services (httpx clients) before closing the loop
        # This prevents "Task exception was never retrieved" / "Event loop is closed" errors
        try:
            from bot.services.ai_selector import AISelector
            loop.run_until_complete(AISelector.close_all_services(clear_cache=True))
        except Exception as e:
            logger.debug(f"Failed to close AI services{ctx}: {e}")

        # Give the loop a chance to process callbacks scheduled by close().
        try:
            loop.run_until_complete(asyncio.sleep(0))
        except Exception:
            pass

        # Drain pending tasks deterministically: wait briefly, then cancel leftovers.
        try:
            pending = [t for t in asyncio.all_tasks(loop) if not t.done()]
            if pending:
                _, still_pending = loop.run_until_complete(asyncio.wait(pending, timeout=1.0))
                if still_pending:
                    for task in still_pending:
                        task.cancel()
                    # Try to await cancellations, but don't hang forever if a task ignores them.
                    try:
                        loop.run_until_complete(
                            asyncio.wait_for(
                                asyncio.gather(*still_pending, return_exceptions=True),
                                timeout=1.0,
                            )
                        )
                    except asyncio.TimeoutError:
                        logger.warning(
                            f"{len(still_pending)} task(s) still pending after cancellation{ctx}; closing loop anyway"
                        )
        except Exception as e:
            logger.error(f"Failed to drain pending tasks{ctx}: {e}", exc_info=True)

        try:
            loop.run_until_complete(asyncio.wait_for(loop.shutdown_asyncgens(), timeout=1.0))
        except asyncio.TimeoutError:
            logger.warning(f"Timeout while shutting down async generators{ctx}; closing loop anyway")
        except Exception as e:
            logger.error(f"Failed to shutdown async generators{ctx}: {e}", exc_info=True)

        shutdown_default_executor = getattr(loop, "shutdown_default_executor", None)
        if shutdown_default_executor is not None:
            try:
                loop.run_until_complete(asyncio.wait_for(shutdown_default_executor(), timeout=1.0))
            except asyncio.TimeoutError:
                logger.warning(f"Timeout while shutting down default executor{ctx}; closing loop anyway")
            except Exception as e:
                logger.error(f"Failed to shutdown default executor{ctx}: {e}", exc_info=True)

    finally:
        try:
            asyncio.set_event_loop(None)
        except Exception:
            pass

        try:
            loop.close()
        except Exception as e:
            logger.error(f"Failed to close event loop{ctx}: {e}", exc_info=True)



@shared_task
def send_monthly_reports():
    """Send monthly expense reports to all users on the 1st day of month at 12:00 for previous month"""
    bot = None
    loop = None

    try:
        from expenses.models import Profile, Expense
        from bot.services.notifications import NotificationService
        from calendar import monthrange
        # Use main bot token for user-facing notifications
        bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') or os.getenv('MONITORING_BOT_TOKEN')
        bot = Bot(token=bot_token)
        service = NotificationService(bot)
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # Use timezone-aware datetime to match CELERY_TIMEZONE (Europe/Moscow)
        now = timezone.now()  # Returns timezone-aware datetime in Europe/Moscow
        today = now.date()

        logger.info(f"Starting monthly reports task for {today}")

        # Calculate previous month period
        if today.month == 1:
            prev_month = 12
            prev_year = today.year - 1
        else:
            prev_month = today.month - 1
            prev_year = today.year

        # Get first and last day of previous month
        month_start = today.replace(year=prev_year, month=prev_month, day=1)
        last_day_of_prev_month = monthrange(prev_year, prev_month)[1]
        month_end = today.replace(year=prev_year, month=prev_month, day=last_day_of_prev_month)

        # Get all active profiles who have expenses in previous month
        # Monthly reports are sent to ALL users with expenses (not just subscribers)
        profiles_with_expenses = Expense.objects.filter(
            expense_date__gte=month_start,
            expense_date__lte=month_end
        ).values_list('profile_id', flat=True).distinct()

        # Get all profiles with expenses (no subscription filter)
        profiles = Profile.objects.filter(
            id__in=profiles_with_expenses
        ).distinct()

        logger.info(f"Sending monthly reports to {profiles.count()} users with expenses")

        for profile in profiles:
            try:
                loop.run_until_complete(
                    service.send_monthly_report_notification(
                        profile.telegram_id,
                        profile,
                        prev_year,
                        prev_month,
                        attempt=1,
                    )
                )
            except Exception as e:
                error_msg = str(e)
                if is_retryable_error(error_msg):
                    logger.warning(
                        f"[MONTHLY_REPORT] user={profile.telegram_id} status=retry_scheduled "
                        f"attempt=1 delay=300s period={prev_year}-{prev_month:02d} error={error_msg}"
                    )
                    retry_send_monthly_report.apply_async(
                        args=[profile.telegram_id, prev_year, prev_month, 2],
                        countdown=300
                    )
                else:
                    logger.error(
                        f"[MONTHLY_REPORT] user={profile.telegram_id} status=failed_permanent "
                        f"period={prev_year}-{prev_month:02d} error={error_msg}"
                    )

    except Exception as e:
        logger.error(f"Error in send_monthly_reports task: {e}")

    finally:
        _shutdown_event_loop(loop, bot=bot, label="send_monthly_reports")


# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è retry –ª–æ–≥–∏–∫–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –º–µ—Å—è—á–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤
RETRYABLE_ERRORS = [
    'internal server error',  # 500
    'bad gateway',            # 502
    'service unavailable',    # 503
    'gateway timeout',        # 504
    'timeout', 'timed out',
    'connection reset',
    'retry after',
    'flood control',
]

NON_RETRYABLE_ERRORS = [
    'forbidden',              # 403 - –±–æ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω
    'chat not found',         # 400 - —á–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    'user is deactivated',    # –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–¥–∞–ª–µ–Ω
    'bot was blocked',
    'have no rights',
    'need administrator',
]

# Backoff: 5 –º–∏–Ω, 30 –º–∏–Ω, 1 —á–∞—Å
RETRY_DELAYS = [300, 1800, 3600]


def is_retryable_error(error_msg: str) -> bool:
    """Check if error is temporary and worth retrying"""
    error_lower = error_msg.lower()

    # First check if it's a non-retryable error
    for pattern in NON_RETRYABLE_ERRORS:
        if pattern in error_lower:
            return False

    # Then check if it matches retryable patterns
    for pattern in RETRYABLE_ERRORS:
        if pattern in error_lower:
            return True

    # Unknown errors - don't retry by default
    return False


@shared_task
def retry_send_monthly_report(user_id: int, year: int, month: int, attempt: int = 1):
    """
    Retry sending monthly report notification.
    Called when initial send fails with a temporary error.

    Backoff schedule: 5 min ‚Üí 30 min ‚Üí 1 hour
    """
    from django.core.cache import cache
    from expenses.models import Profile
    from bot.services.notifications import NotificationService

    bot = None
    loop = None

    # Idempotency check - don't send duplicates
    sent_key = f"monthly_report_sent:{user_id}:{year}:{month}"
    if cache.get(sent_key):
        logger.info(f"[MONTHLY_REPORT] user={user_id} status=already_sent period={year}-{month:02d}")
        return

    try:
        bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') or os.getenv('MONITORING_BOT_TOKEN')
        bot = Bot(token=bot_token)
        service = NotificationService(bot)
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        profile = Profile.objects.get(telegram_id=user_id)

        sent = loop.run_until_complete(
            service.send_monthly_report_notification(
                profile.telegram_id,
                profile,
                year,
                month,
                attempt=attempt,
            )
        )
        if not sent:
            logger.info(
                f"[MONTHLY_REPORT] user={user_id} status=skipped "
                f"attempt={attempt} period={year}-{month:02d}"
            )

    except Profile.DoesNotExist:
        logger.error(f"[MONTHLY_REPORT] user={user_id} status=failed error=profile_not_found")

    except Exception as e:
        error_msg = str(e)

        if is_retryable_error(error_msg):
            if attempt < 4:  # Max 4 attempts total (1 initial + 3 retries)
                delay = RETRY_DELAYS[min(attempt - 1, len(RETRY_DELAYS) - 1)]
                logger.warning(
                    f"[MONTHLY_REPORT] user={user_id} status=retry_scheduled "
                    f"attempt={attempt} next_attempt={attempt + 1} delay={delay}s error={error_msg}"
                )
                # Schedule next retry
                retry_send_monthly_report.apply_async(
                    args=[user_id, year, month, attempt + 1],
                    countdown=delay
                )
            else:
                # All retries exhausted
                logger.error(
                    f"[MONTHLY_REPORT] user={user_id} status=failed "
                    f"attempts={attempt} period={year}-{month:02d} error={error_msg}"
                )
                # Alert admin
                try:
                    from bot.services.admin_notifier import send_admin_alert
                    loop.run_until_complete(
                        send_admin_alert(
                            f"‚ùå Monthly report FAILED after {attempt} attempts\n"
                            f"User: {user_id}\n"
                            f"Period: {year}-{month:02d}\n"
                            f"Error: {error_msg}",
                            disable_notification=True
                        )
                    )
                except Exception as alert_err:
                    logger.error(f"Failed to send admin alert: {alert_err}")
        else:
            # Non-retryable error (user blocked bot, etc.)
            logger.error(
                f"[MONTHLY_REPORT] user={user_id} status=failed_permanent "
                f"period={year}-{month:02d} error={error_msg}"
            )

    finally:
        _shutdown_event_loop(loop, bot=bot, label="retry_send_monthly_report")


@shared_task
def generate_monthly_insights():
    """Generate AI insights for all active subscribers on the 1st day of month at 11:00 for previous month"""
    loop = None
    try:
        from expenses.models import Profile, Expense
        from bot.services.monthly_insights import MonthlyInsightsService
        from calendar import monthrange

        # Use timezone-aware datetime to match CELERY_TIMEZONE (Europe/Moscow)
        now = timezone.now()
        today = now.date()

        logger.info(f"Starting monthly insights generation for {today}")

        # Calculate previous month period
        if today.month == 1:
            prev_month = 12
            prev_year = today.year - 1
        else:
            prev_month = today.month - 1
            prev_year = today.year

        # Get first and last day of previous month
        month_start = today.replace(year=prev_year, month=prev_month, day=1)
        last_day_of_prev_month = monthrange(prev_year, prev_month)[1]
        month_end = today.replace(year=prev_year, month=prev_month, day=last_day_of_prev_month)

        # Get profiles with expenses in previous month
        # Monthly insights are generated for ALL users with expenses (not just subscribers)
        profiles_with_expenses = Expense.objects.filter(
            expense_date__gte=month_start,
            expense_date__lte=month_end
        ).values_list('profile_id', flat=True).distinct()

        # Get all profiles with expenses (no subscription filter)
        profiles = Profile.objects.filter(
            id__in=profiles_with_expenses
        ).distinct()

        logger.info(f"Generating AI insights for {profiles.count()} users with expenses")

        # Initialize service
        service = MonthlyInsightsService()

        # Run async function in sync context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        success_count = 0
        fail_count = 0

        insights_provider = os.getenv('AI_PROVIDER_INSIGHTS') or os.getenv('AI_PROVIDER_DEFAULT') or 'deepseek'
        insights_provider = insights_provider.lower()
        valid_providers = {'google', 'openai', 'deepseek', 'qwen', 'openrouter'}
        if insights_provider not in valid_providers:
            logger.warning(f"Unknown AI provider for insights: {insights_provider}, falling back to deepseek")
            insights_provider = 'deepseek'

        for profile in profiles:
            try:
                insight = loop.run_until_complete(
                    service.generate_insight(
                        profile=profile,
                        year=prev_year,
                        month=prev_month,
                        provider=insights_provider,
                        force_regenerate=False
                    )
                )

                if insight:
                    success_count += 1
                    logger.info(f"Generated insight for user {profile.telegram_id} for {prev_month}/{prev_year}")
                else:
                    logger.info(f"Skipped insight for user {profile.telegram_id} (insufficient data or no subscription)")

            except Exception as e:
                fail_count += 1
                logger.error(f"Error generating insight for user {profile.telegram_id}: {e}")

        logger.info(f"Insights generation completed: {success_count} successful, {fail_count} failed")

    except Exception as e:
        logger.error(f"Error in generate_monthly_insights task: {e}")

    finally:
        _shutdown_event_loop(loop, label="generate_monthly_insights")


@shared_task
def cleanup_old_expenses():
    """Clean up expenses older than retention period"""
    try:
        from expenses.models import Expense
        from datetime import timedelta
        
        # Keep expenses for 2 years by default
        retention_days = getattr(settings, 'EXPENSE_RETENTION_DAYS', 730)
        cutoff_date = date.today() - timedelta(days=retention_days)
        
        # Delete old expenses
        deleted_count, _ = Expense.objects.filter(
            created_at__lt=cutoff_date
        ).delete()
        
        logger.info(f"Deleted {deleted_count} expenses older than {cutoff_date}")
        
    except Exception as e:
        logger.error(f"Error in cleanup_old_expenses task: {e}")


@shared_task
def send_daily_admin_report():
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    try:
        from expenses.models import (
            Profile, Expense, ExpenseCategory, Subscription, Income,
            UserAnalytics, AIServiceMetrics, SystemHealthCheck, 
            AffiliateCommission, RecurringPayment
        )
        from bot.services.admin_notifier import send_admin_alert, escape_markdown_v2
        from django.utils import timezone
        from django.db.models import Q, Avg, Max, Min
        from datetime import timedelta
        import json

        def esc(v) -> str:
            return escape_markdown_v2(str(v))

        yesterday = timezone.localdate() - timedelta(days=1)
        today = timezone.localdate()
        week_ago = yesterday - timedelta(days=7)
        yesterday_start = timezone.make_aware(datetime.combine(yesterday, datetime.min.time()))
        yesterday_end = timezone.make_aware(datetime.combine(yesterday, datetime.max.time()))

        # ===============================
        # –ë–ê–ó–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô
        # ===============================
        total_users = Profile.objects.count()
        active_users = Expense.objects.filter(
            expense_date=yesterday
        ).values('profile').distinct().count()

        new_users = Profile.objects.filter(
            created_at__date=yesterday
        ).count()

        # WAU (Weekly Active Users) - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –∑–∞ –Ω–µ–¥–µ–ª—é
        weekly_active_users = Expense.objects.filter(
            expense_date__gte=week_ago,
            expense_date__lte=yesterday
        ).values('profile').distinct().count()

        # Retention: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏, –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–µ–¥–µ–ª—é –Ω–∞–∑–∞–¥ –∏ –∞–∫—Ç–∏–≤–Ω—ã–µ –≤—á–µ—Ä–∞
        week_ago_users = Profile.objects.filter(created_at__date=week_ago).values_list('id', flat=True)
        retained_users = Expense.objects.filter(
            profile_id__in=week_ago_users,
            expense_date=yesterday
        ).values('profile').distinct().count()
        retention_rate = (retained_users / len(week_ago_users) * 100) if week_ago_users else 0

        # ===============================
        # –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–°–•–û–î–û–í –ò –î–û–•–û–î–û–í
        # ===============================
        expenses_stats = Expense.objects.filter(
            expense_date=yesterday
        ).aggregate(
            total=Sum('amount'),
            count=Count('id'),
            avg=Avg('amount'),
            max_expense=Max('amount'),
            ai_categorized=Count('id', filter=Q(ai_categorized=True))
        )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ—Ö–æ–¥–∞–º
        incomes_stats = Income.objects.filter(
            income_date=yesterday
        ).aggregate(
            total=Sum('amount'),
            count=Count('id'),
            avg=Avg('amount')
        )

        # AI –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        ai_accuracy_rate = 0
        if expenses_stats['count'] and expenses_stats['count'] > 0:
            ai_accuracy_rate = (expenses_stats['ai_categorized'] / expenses_stats['count']) * 100

        # ===============================
        # –ü–û–î–ü–ò–°–ö–ò –ò –§–ò–ù–ê–ù–°–´
        # ===============================
        new_subscriptions = Subscription.objects.filter(
            created_at__date=yesterday,
            payment_method__in=['stars', 'referral', 'promo']
        ).values('type').annotate(
            count=Count('id')
        ).order_by('type')

        # –ü–æ–¥—Å—á–µ—Ç –ø–æ–¥–ø–∏—Å–æ–∫ –ø–æ —Ç–∏–ø–∞–º
        subs_month = 0
        subs_six_months = 0
        subscription_revenue = 0
        
        for sub in new_subscriptions:
            if sub['type'] == 'month':
                subs_month = sub['count']
                subscription_revenue += sub['count'] * 150  # 150 –∑–≤–µ–∑–¥ –∑–∞ –º–µ—Å—è—á–Ω—É—é
            elif sub['type'] == 'six_months':
                subs_six_months = sub['count']
                subscription_revenue += sub['count'] * 750  # 750 –∑–≤–µ–∑–¥ –∑–∞ –ø–æ–ª—É–≥–æ–¥–æ–≤—É—é

        active_subscriptions = Subscription.objects.filter(
            is_active=True,
            end_date__gt=timezone.now()
        ).count()

        # –ü–æ–¥–ø–∏—Å–∫–∏ –∏—Å—Ç–µ–∫–∞—é—â–∏–µ –≤ –±–ª–∏–∂–∞–π—à–∏–µ 3 –¥–Ω—è
        expiring_soon = Subscription.objects.filter(
            is_active=True,
            end_date__lte=timezone.now() + timedelta(days=3),
            end_date__gt=timezone.now()
        ).count()

        # ===============================
        # –†–ï–§–ï–†–ê–õ–¨–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê
        # ===============================
        affiliate_stats = AffiliateCommission.objects.filter(
            created_at__date=yesterday
        ).aggregate(
            new_commissions=Count('id'),
            total_commission_amount=Sum('commission_amount'),
            paid_commissions=Count('id', filter=Q(status='paid')),
            hold_commissions=Count('id', filter=Q(status='hold'))
        )

        # ===============================
        # AI –°–ï–†–í–ò–°–´ –ú–û–ù–ò–¢–û–†–ò–ù–ì
        # ===============================
        ai_metrics = AIServiceMetrics.objects.filter(
            timestamp__gte=yesterday_start,
            timestamp__lte=yesterday_end
        ).aggregate(
            total_requests=Count('id'),
            successful_requests=Count('id', filter=Q(success=True)),
            avg_response_time=Avg('response_time'),
            max_response_time=Max('response_time'),
            total_tokens=Sum('tokens_used'),
            total_cost=Sum('estimated_cost')
        )

        ai_success_rate = 0
        if ai_metrics['total_requests']:
            ai_success_rate = (ai_metrics['successful_requests'] / ai_metrics['total_requests']) * 100

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–µ—Ä–≤–∏—Å–∞–º
        openai_stats = AIServiceMetrics.objects.filter(
            timestamp__gte=yesterday_start,
            timestamp__lte=yesterday_end,
            service='openai'
        ).aggregate(
            requests=Count('id'),
            avg_time=Avg('response_time'),
            success_rate=Avg(Case(
                When(success=True, then=1.0),
                When(success=False, then=0.0),
                output_field=FloatField()
            ))
        )

        google_stats = AIServiceMetrics.objects.filter(
            timestamp__gte=yesterday_start,
            timestamp__lte=yesterday_end,
            service='google'
        ).aggregate(
            requests=Count('id'),
            avg_time=Avg('response_time'),
            success_rate=Avg(Case(
                When(success=True, then=1.0),
                When(success=False, then=0.0),
                output_field=FloatField()
            ))
        )

        deepseek_stats = AIServiceMetrics.objects.filter(
            timestamp__gte=yesterday_start,
            timestamp__lte=yesterday_end,
            service='deepseek'
        ).aggregate(
            requests=Count('id'),
            avg_time=Avg('response_time'),
            success_rate=Avg(Case(
                When(success=True, then=1.0),
                When(success=False, then=0.0),
                output_field=FloatField()
            ))
        )

        qwen_stats = AIServiceMetrics.objects.filter(
            timestamp__gte=yesterday_start,
            timestamp__lte=yesterday_end,
            service='qwen'
        ).aggregate(
            requests=Count('id'),
            avg_time=Avg('response_time'),
            success_rate=Avg(Case(
                When(success=True, then=1.0),
                When(success=False, then=0.0),
                output_field=FloatField()
            ))
        )

        # ===============================
        # –°–ò–°–¢–ï–ú–ê –ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨
        # ===============================
        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã
        latest_health_check = SystemHealthCheck.objects.filter(
            timestamp__gte=yesterday_start
        ).order_by('-timestamp').first()

        system_status = "‚ùì –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        if latest_health_check:
            status_emoji = {
                'healthy': '‚úÖ',
                'degraded': '‚ö†Ô∏è',
                'unhealthy': 'üö®'
            }
            system_status = f"{status_emoji.get(latest_health_check.overall_status, '‚ùì')} {latest_health_check.overall_status.title()}"

        # ===============================
        # –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨–°–ö–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê
        # ===============================
        user_analytics = UserAnalytics.objects.filter(
            date=yesterday
        ).aggregate(
            total_messages=Sum('messages_sent'),
            total_voice_messages=Sum('voice_messages'),
            total_photos=Sum('photos_sent'),
            total_expenses_added=Sum('expenses_added'),
            total_incomes_added=Sum('incomes_added'),
            total_errors=Sum('errors_encountered'),
            total_pdf_reports=Sum('pdf_reports_generated'),
            total_cashback_calculated=Sum('cashback_calculated'),
            active_users_analytics=Count('profile', distinct=True)
        )

        # ===============================
        # –†–ï–ì–£–õ–Ø–†–ù–´–ï –ü–õ–ê–¢–ï–ñ–ò
        # ===============================
        recurring_payments_processed = RecurringPayment.objects.filter(
            last_processed=yesterday
        ).count()

        # ===============================
        # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –û–¢–ß–ï–¢–ê
        # ===============================
        count_formatted = f"{(expenses_stats['count'] or 0):,}"
        total_formatted = f"{(expenses_stats['total'] or 0):,.0f}"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ç–æ—á–µ–∫
        date_formatted = yesterday.strftime('%d.%m.%Y').replace('.', '\\.')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = (
            f"üìä \*–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç ExpenseBot\*\n"
            f"üìÖ –ó–∞ {date_formatted}\n\n"
            
            f"üë• \*–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:\*\n"
            f"  ‚Ä¢ –í—Å–µ–≥–æ: {esc(f'{total_users:,}')}\n"
            f"  ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –≤—á–µ—Ä–∞: {esc(active_users)}\n"
            f"  ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞ –Ω–µ–¥–µ–ª—é: {esc(weekly_active_users)}\n"
            f"  ‚Ä¢ –ù–æ–≤—ã—Ö —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–π: {esc(new_users)}\n"
            f"  ‚Ä¢ Retention \\(7d\\): {esc(f'{retention_rate:.1f}%')}\n\n"
            
            f"‚≠ê \*–ü–æ–¥–ø–∏—Å–∫–∏:\*\n"
            f"  ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –≤—Å–µ–≥–æ: {esc(active_subscriptions)}\n"
            f"  ‚Ä¢ –ò—Å—Ç–µ–∫–∞—é—Ç –≤ 3 –¥–Ω—è: {esc(expiring_soon)}\n"
            f"  ‚Ä¢ –ö—É–ø–ª–µ–Ω–æ –≤—á–µ—Ä–∞ \\(1 –º–µ—Å\\.\\): {esc(subs_month)}\n"
            f"  ‚Ä¢ –ö—É–ø–ª–µ–Ω–æ –≤—á–µ—Ä–∞ \\(6 –º–µ—Å\\.\\): {esc(subs_six_months)}\n"
        )
        
        if subscription_revenue > 0:
            report += f"  ‚Ä¢ –î–æ—Ö–æ–¥ —Å –ø–æ–¥–ø–∏—Å–æ–∫: {esc(subscription_revenue)} ‚≠ê\n"

        # –†–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞
        if affiliate_stats['new_commissions']:
            report += (
                f"\nüíº \*–†–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞:\*\n"
                f"  ‚Ä¢ –ù–æ–≤—ã—Ö –∫–æ–º–∏—Å—Å–∏–π: {esc(affiliate_stats['new_commissions'])}\n"
                f"  ‚Ä¢ –°—É–º–º–∞ –∫–æ–º–∏—Å—Å–∏–π: {esc(affiliate_stats['total_commission_amount'] or 0)} ‚≠ê\n"
                f"  ‚Ä¢ –ù–∞ —Ö–æ–ª–¥–µ: {esc(affiliate_stats['hold_commissions'])}\n"
            )

        # AI —Å–µ—Ä–≤–∏—Å—ã
        if ai_metrics['total_requests']:
            avg_resp_time = ai_metrics.get('avg_response_time', 0) or 0
            total_tokens = ai_metrics.get('total_tokens', 0) or 0
            report += (
                f"\nü§ñ \*AI —Å–µ—Ä–≤–∏—Å—ã:\*\n"
                f"  ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {esc(ai_metrics['total_requests'])}\n"
                f"  ‚Ä¢ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {esc(f'{ai_success_rate:.1f}%')}\n"
                f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {esc(f'{avg_resp_time:.2f}')}—Å\n"
                f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {esc(f'{total_tokens:,}')}\n"
            )
            
            if ai_metrics.get('total_cost'):
                total_cost = ai_metrics.get('total_cost', 0) or 0
                report += f"  ‚Ä¢ –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${esc(f'{total_cost:.3f}')}\n"
                
            if openai_stats['requests'] or google_stats['requests'] or deepseek_stats['requests'] or qwen_stats['requests']:
                openai_success = (openai_stats.get('success_rate') or 0) * 100
                google_success = (google_stats.get('success_rate') or 0) * 100
                deepseek_success = (deepseek_stats.get('success_rate') or 0) * 100
                qwen_success = (qwen_stats.get('success_rate') or 0) * 100
                
                if openai_stats['requests']:
                    report += (
                        f"  ‚Ä¢ OpenAI: {esc(openai_stats['requests'])} –∑–∞–ø\\., "
                        f"{esc(f'{openai_success:.0f}')}% —É—Å–ø–µ—Ö\n"
                    )
                if google_stats['requests']:
                    report += (
                        f"  ‚Ä¢ Google: {esc(google_stats['requests'])} –∑–∞–ø\\., "
                        f"{esc(f'{google_success:.0f}')}% —É—Å–ø–µ—Ö\n"
                    )
                if deepseek_stats['requests']:
                    report += (
                        f"  ‚Ä¢ DeepSeek: {esc(deepseek_stats['requests'])} –∑–∞–ø\\., "
                        f"{esc(f'{deepseek_success:.0f}')}% —É—Å–ø–µ—Ö\n"
                    )
                if qwen_stats['requests']:
                    report += (
                        f"  ‚Ä¢ Qwen: {esc(qwen_stats['requests'])} –∑–∞–ø\\., "
                        f"{esc(f'{qwen_success:.0f}')}% —É—Å–ø–µ—Ö\n"
                    )

        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        if user_analytics['active_users_analytics']:
            report += (
                f"\nüìà \*–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:\*\n"
                f"  ‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π: {esc(user_analytics['total_messages'] or 0)}\n"
                f"  ‚Ä¢ –ì–æ–ª–æ—Å–æ–≤—ã—Ö: {esc(user_analytics['total_voice_messages'] or 0)}\n"
                f"  ‚Ä¢ –§–æ—Ç–æ: {esc(user_analytics['total_photos'] or 0)}\n"
                f"  ‚Ä¢ AI –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è: {esc(f'{ai_accuracy_rate:.1f}%')}\n"
            )
            
            if user_analytics['total_pdf_reports']:
                report += f"  ‚Ä¢ PDF –æ—Ç—á–µ—Ç–æ–≤: {esc(user_analytics['total_pdf_reports'])}\n"
            
            if user_analytics['total_cashback_calculated']:
                cashback_calc = user_analytics['total_cashback_calculated']
                report += f"  ‚Ä¢ –ö–µ—à–±—ç–∫ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω: {esc(f'{cashback_calc:.0f}')} ‚ÇΩ\n"

        # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∏
        if recurring_payments_processed > 0:
            report += f"\nüîÑ \*–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∏:\* {esc(recurring_payments_processed)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ\n"

        # –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
        report += f"\n‚ö° \*–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:\* {esc(system_status)}\n"

        # –û—à–∏–±–∫–∏
        if user_analytics['total_errors']:
            report += f"\n‚ö†Ô∏è \*–û—à–∏–±–∫–∏:\* {esc(user_analytics['total_errors'])} –∑–∞ –¥–µ–Ω—å\n"

        report += f"\n‚è∞ –û—Ç—á–µ—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω: {esc(datetime.now().strftime('%H:%M'))}"

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(send_admin_alert(report, disable_notification=True))
        finally:
            _shutdown_event_loop(loop, label="send_daily_admin_report")

        logger.info(f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç –∑–∞ {yesterday} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}", exc_info=True)


@shared_task
def system_health_check():
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫"""
    try:
        from expenses.models import SystemHealthCheck, AIServiceMetrics
        from django.db import connection
        from django.core.cache import cache
        from django.utils import timezone
        from django.conf import settings
        import redis
        import requests
        import psutil
        import os
        from datetime import timedelta
        
        logger.info("–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã")
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        check_start = timezone.now()
        issues = []
        
        # =====================================
        # 1. –ë–ê–ó–ê –î–ê–ù–ù–´–•
        # =====================================
        database_status = False
        database_response_time = None
        try:
            db_start = timezone.now()
            with connection.cursor() as cursor:
                cursor.execute("SELECT COUNT(*) FROM users_profile")
                result = cursor.fetchone()
            database_response_time = (timezone.now() - db_start).total_seconds()
            database_status = True
            logger.info(f"Database check: OK ({database_response_time:.3f}s)")
        except Exception as e:
            logger.error(f"Database check failed: {e}")
            issues.append(f"Database connection failed: {str(e)[:100]}")
        
        # =====================================
        # 2. REDIS
        # =====================================
        redis_status = False
        redis_response_time = None
        redis_memory_usage = None
        try:
            redis_start = timezone.now()
            r = redis.Redis(
                host=getattr(settings, 'REDIS_HOST', 'localhost'),
                port=int(getattr(settings, 'REDIS_PORT', 6379)),
                db=0,
                socket_connect_timeout=5
            )
            r.ping()
            redis_response_time = (timezone.now() - redis_start).total_seconds()
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏
            info = r.info('memory')
            redis_memory_usage = info.get('used_memory', 0)
            
            redis_status = True
            logger.info(f"Redis check: OK ({redis_response_time:.3f}s, {redis_memory_usage//1024//1024}MB)")
        except Exception as e:
            logger.error(f"Redis check failed: {e}")
            issues.append(f"Redis connection failed: {str(e)[:100]}")
        
        # =====================================
        # 3. TELEGRAM API
        # =====================================
        telegram_api_status = False
        telegram_api_response_time = None
        try:
            telegram_start = timezone.now()
            bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN')
            if bot_token:
                response = requests.get(
                    f"https://api.telegram.org/bot{bot_token}/getMe",
                    timeout=10
                )
                if response.status_code == 200:
                    telegram_api_response_time = (timezone.now() - telegram_start).total_seconds()
                    telegram_api_status = True
                    logger.info(f"Telegram API check: OK ({telegram_api_response_time:.3f}s)")
                else:
                    issues.append(f"Telegram API returned status {response.status_code}")
            else:
                issues.append("Telegram bot token not configured")
        except Exception as e:
            logger.error(f"Telegram API check failed: {e}")
            issues.append(f"Telegram API check failed: {str(e)[:100]}")
        
        # =====================================
        # 4. OPENAI API
        # =====================================
        openai_api_status = False
        openai_api_response_time = None
        try:
            openai_start = timezone.now()
            openai_key = os.getenv('OPENAI_API_KEY')
            if openai_key:
                response = requests.get(
                    "https://api.openai.com/v1/models",
                    headers={"Authorization": f"Bearer {openai_key}"},
                    timeout=10
                )
                if response.status_code == 200:
                    openai_api_response_time = (timezone.now() - openai_start).total_seconds()
                    openai_api_status = True
                    logger.info(f"OpenAI API check: OK ({openai_api_response_time:.3f}s)")
                else:
                    issues.append(f"OpenAI API returned status {response.status_code}")
            else:
                logger.info("OpenAI API key not configured - skipping check")
        except Exception as e:
            logger.error(f"OpenAI API check failed: {e}")
            issues.append(f"OpenAI API check failed: {str(e)[:100]}")
        
        # =====================================
        # 5. GOOGLE AI API
        # =====================================
        google_ai_api_status = False
        google_ai_api_response_time = None
        try:
            google_start = timezone.now()
            google_key = os.getenv('GOOGLE_AI_KEY')
            if google_key:
                # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API
                response = requests.get(
                    f"https://generativelanguage.googleapis.com/v1beta/models?key={google_key}",
                    timeout=10
                )
                if response.status_code == 200:
                    google_ai_api_response_time = (timezone.now() - google_start).total_seconds()
                    google_ai_api_status = True
                    logger.info(f"Google AI API check: OK ({google_ai_api_response_time:.3f}s)")
                else:
                    issues.append(f"Google AI API returned status {response.status_code}")
            else:
                logger.info("Google AI API key not configured - skipping check")
        except Exception as e:
            logger.error(f"Google AI API check failed: {e}")
            issues.append(f"Google AI API check failed: {str(e)[:100]}")

        # =====================================
        # 5a. DEEPSEEK API
        # =====================================
        deepseek_api_status = False
        deepseek_api_response_time = None
        try:
            ds_start = timezone.now()
            ds_key = os.getenv('DEEPSEEK_API_KEY')
            if ds_key:
                response = requests.get(
                    "https://api.deepseek.com/v1/models",
                    headers={"Authorization": f"Bearer {ds_key}"},
                    timeout=10
                )
                if response.status_code == 200:
                    deepseek_api_response_time = (timezone.now() - ds_start).total_seconds()
                    deepseek_api_status = True
                    logger.info(f"DeepSeek API check: OK ({deepseek_api_response_time:.3f}s)")
                else:
                    issues.append(f"DeepSeek API returned status {response.status_code}")
            else:
                logger.info("DeepSeek API key not configured - skipping check")
        except Exception as e:
            logger.error(f"DeepSeek API check failed: {e}")
            issues.append(f"DeepSeek API check failed: {str(e)[:100]}")

        # =====================================
        # 5b. QWEN (DASHSCOPE) API
        # =====================================
        qwen_api_status = False
        qwen_api_response_time = None
        try:
            qwen_start = timezone.now()
            qwen_key = os.getenv('DASHSCOPE_API_KEY')
            if qwen_key:
                # DashScope requires explicit model access usually, but we can try a simple list or specific model info
                # Correct endpoint for DashScope is strict. Trying compatible-mode endpoint.
                response = requests.get(
                    "https://dashscope-intl.aliyuncs.com/compatible-mode/v1/models",
                    headers={"Authorization": f"Bearer {qwen_key}"},
                    timeout=10
                )
                if response.status_code == 200:
                    qwen_api_response_time = (timezone.now() - qwen_start).total_seconds()
                    qwen_api_status = True
                    logger.info(f"Qwen API check: OK ({qwen_api_response_time:.3f}s)")
                else:
                    issues.append(f"Qwen API returned status {response.status_code}")
            else:
                logger.info("Qwen API key not configured - skipping check")
        except Exception as e:
            logger.error(f"Qwen API check failed: {e}")
            issues.append(f"Qwen API check failed: {str(e)[:100]}")
        
        # =====================================
        # 6. CELERY
        # =====================================
        celery_status = False
        celery_workers_count = None
        celery_queue_size = None
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º celery app
            from expense_bot.celery import app
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–æ—Ä–∫–µ—Ä–∞—Ö
            inspect = app.control.inspect()
            stats = inspect.stats()
            
            if stats:
                celery_workers_count = len(stats)
                celery_status = True
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–µ–π
                active_queues = inspect.active_queues()
                queue_lengths = {}
                for worker, queues in (active_queues or {}).items():
                    for queue in queues:
                        queue_name = queue.get('name', 'default')
                        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –æ—á–µ—Ä–µ–¥–∏ –∏–∑ Redis
                        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞ –µ—Å–ª–∏ –≤–æ—Ä–∫–µ—Ä—ã –∞–∫—Ç–∏–≤–Ω—ã
                        queue_lengths[queue_name] = 0
                
                celery_queue_size = sum(queue_lengths.values())
                logger.info(f"Celery check: OK ({celery_workers_count} workers)")
            else:
                issues.append("No active Celery workers found")
        except Exception as e:
            logger.error(f"Celery check failed: {e}")
            issues.append(f"Celery check failed: {str(e)[:100]}")
        
        # =====================================
        # 7. –°–ò–°–¢–ï–ú–ù–´–ï –ú–ï–¢–†–ò–ö–ò
        # =====================================
        disk_free_gb = None
        memory_usage_percent = None
        cpu_usage_percent = None
        try:
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–∞
            disk_usage = psutil.disk_usage('/')
            disk_free_gb = disk_usage.free / (1024**3)  # –í –≥–∏–≥–∞–±–∞–π—Ç–∞—Ö
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
            memory = psutil.virtual_memory()
            memory_usage_percent = memory.percent
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU (—Å—Ä–µ–¥–Ω–µ–µ –∑–∞ 1 —Å–µ–∫—É–Ω–¥—É)
            cpu_usage_percent = psutil.cpu_percent(interval=1)
            
            logger.info(f"System metrics: {disk_free_gb:.1f}GB free, {memory_usage_percent:.1f}% RAM, {cpu_usage_percent:.1f}% CPU")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            if disk_free_gb < 1.0:  # –ú–µ–Ω—å—à–µ 1 –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
                issues.append(f"Low disk space: {disk_free_gb:.1f}GB free")
            
            if memory_usage_percent > 90:
                issues.append(f"High memory usage: {memory_usage_percent:.1f}%")
            
            if cpu_usage_percent > 80:
                issues.append(f"High CPU usage: {cpu_usage_percent:.1f}%")
                
        except Exception as e:
            logger.error(f"System metrics collection failed: {e}")
            issues.append(f"System metrics failed: {str(e)[:100]}")
        
        # =====================================
        # 8. –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –û–ë–©–ï–ì–û –°–¢–ê–¢–£–°–ê
        # =====================================
        critical_components = [database_status, redis_status]
        important_components = [telegram_api_status, celery_status]
        
        if all(critical_components):
            if all(important_components):
                overall_status = 'healthy'
            else:
                overall_status = 'degraded'
        else:
            overall_status = 'unhealthy'
        
        # =====================================
        # 9. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
        # =====================================
        health_check = SystemHealthCheck.objects.create(
            timestamp=check_start,
            database_status=database_status,
            database_response_time=database_response_time,
            redis_status=redis_status,
            redis_response_time=redis_response_time,
            redis_memory_usage=redis_memory_usage,
            telegram_api_status=telegram_api_status,
            telegram_api_response_time=telegram_api_response_time,
            openai_api_status=openai_api_status,
            openai_api_response_time=openai_api_response_time,
            google_ai_api_status=google_ai_api_status,
            google_ai_api_response_time=google_ai_api_response_time,
            deepseek_api_status=deepseek_api_status,
            deepseek_api_response_time=deepseek_api_response_time,
            qwen_api_status=qwen_api_status,
            qwen_api_response_time=qwen_api_response_time,
            celery_status=celery_status,
            celery_workers_count=celery_workers_count,
            celery_queue_size=celery_queue_size,
            disk_free_gb=disk_free_gb,
            memory_usage_percent=memory_usage_percent,
            cpu_usage_percent=cpu_usage_percent,
            overall_status=overall_status,
            issues=issues
        )
        
        # =====================================
        # 10. –û–¢–ü–†–ê–í–ö–ê –ê–õ–ï–†–¢–û–í –ï–°–õ–ò –ù–ï–û–ë–•–û–î–ò–ú–û
        # =====================================
        if overall_status in ['unhealthy', 'degraded'] or issues:
            try:
                from bot.services.admin_notifier import send_admin_alert, escape_markdown_v2
                
                status_emoji = {'healthy': '‚úÖ', 'degraded': '‚ö†Ô∏è', 'unhealthy': 'üö®'}
                
                alert_message = (
                    f"{status_emoji.get(overall_status, '‚ùì')} *–°–∏—Å—Ç–µ–º–Ω—ã–π –∞–ª–µ—Ä—Ç*\n\n"
                    f"–°—Ç–∞—Ç—É—Å: {escape_markdown_v2(overall_status.title())}\n"
                    f"–í—Ä–µ–º—è: {escape_markdown_v2(check_start.strftime('%H:%M:%S'))}\n\n"
                )
                
                if issues:
                    alert_message += "*–ü—Ä–æ–±–ª–µ–º—ã:*\n"
                    for issue in issues[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º
                        alert_message += f"‚Ä¢ {escape_markdown_v2(issue)}\n"
                    
                    if len(issues) > 5:
                        alert_message += f"‚Ä¢ ... –∏ –µ—â–µ {len(issues) - 5} –ø—Ä–æ–±–ª–µ–º\n"
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–ª–µ—Ä—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    loop.run_until_complete(send_admin_alert(alert_message))
                finally:
                    _shutdown_event_loop(loop, label="system_health_check")
                
                logger.warning(f"System health alert sent: {overall_status} with {len(issues)} issues")
            
            except Exception as e:
                logger.error(f"Failed to send health alert: {e}")
        
        # =====================================
        # 11. –û–ß–ò–°–¢–ö–ê –°–¢–ê–†–´–• –ó–ê–ü–ò–°–ï–ô
        # =====================================
        try:
            # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
            old_threshold = timezone.now() - timedelta(days=30)
            deleted_count, _ = SystemHealthCheck.objects.filter(
                timestamp__lt=old_threshold
            ).delete()
            
            if deleted_count > 0:
                logger.info(f"Deleted {deleted_count} old health check records")
        
        except Exception as e:
            logger.error(f"Failed to cleanup old health checks: {e}")
        
        total_time = (timezone.now() - check_start).total_seconds()
        logger.info(f"System health check completed in {total_time:.2f}s: {overall_status}")
        
        return {
            'status': overall_status,
            'timestamp': check_start.isoformat(),
            'total_time': total_time,
            'issues_count': len(issues)
        }
        
    except Exception as e:
        logger.error(f"System health check task failed: {e}", exc_info=True)
        return {'status': 'error', 'error': str(e)}


@shared_task
def collect_daily_analytics():
    """–°–±–æ—Ä –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞ –¥–µ–Ω—å (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ –¥–Ω—è)"""
    try:
        from expenses.models import (
            Profile, Expense, Income, UserAnalytics, 
            AIServiceMetrics, Subscription, AffiliateCommission
        )
        from django.utils import timezone
        from django.db.models import Count, Sum, Avg, Q
        from datetime import timedelta
        import json

        logger.info("–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")
        
        # –í—á–µ—Ä–∞—à–Ω—è—è –¥–∞—Ç–∞ (–¥–∞–Ω–Ω—ã–µ –∑–∞ –∫–æ—Ç–æ—Ä—É—é —Å–æ–±–∏—Ä–∞–µ–º)
        target_date = timezone.localdate() - timedelta(days=1)
        target_start = timezone.make_aware(datetime.combine(target_date, time.min))
        target_end = timezone.make_aware(datetime.combine(target_date, time.max))
        
        processed_profiles = 0
        created_analytics = 0
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –∞–∫—Ç–∏–≤–Ω—ã –≤—á–µ—Ä–∞
        # (–¥–æ–±–∞–≤–ª—è–ª–∏ —Ä–∞—Å—Ö–æ–¥—ã, –¥–æ—Ö–æ–¥—ã, –∏–ª–∏ –∏–º–µ–ª–∏ –¥—Ä—É–≥—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å)
        active_profiles = Profile.objects.filter(
            Q(expenses__created_at__gte=target_start, expenses__created_at__lte=target_end) |
            Q(incomes__created_at__gte=target_start, incomes__created_at__lte=target_end) |
            Q(subscriptions__created_at__gte=target_start, subscriptions__created_at__lte=target_end)
        ).distinct()
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {active_profiles.count()} –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∑–∞ {target_date}")
        
        for profile in active_profiles:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ –∑–∞–ø–∏—Å–∏ –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å
                existing_analytics = UserAnalytics.objects.filter(
                    profile=profile,
                    date=target_date
                ).first()
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–∞—Å—Ö–æ–¥–∞–º
                expenses = Expense.objects.filter(
                    profile=profile,
                    created_at__gte=target_start,
                    created_at__lte=target_end
                )
                
                expenses_stats = expenses.aggregate(
                    count=Count('id'),
                    ai_categorized_count=Count('id', filter=Q(ai_categorized=True)),
                    manual_categorized_count=Count('id', filter=Q(ai_categorized=False)),
                )
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–æ—Ö–æ–¥–∞–º
                incomes = Income.objects.filter(
                    profile=profile,
                    created_at__gte=target_start,
                    created_at__lte=target_end
                )
                
                incomes_count = incomes.count()
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (—Ç–æ–ø-5 –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö)
                categories_used = {}
                for expense in expenses:
                    if expense.category:
                        cat_id = str(expense.category.id)
                        categories_used[cat_id] = categories_used.get(cat_id, 0) + 1
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ AI —Å–µ—Ä–≤–∏—Å–∞–º (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ - –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É AI –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–π)
                ai_categorizations = expenses_stats['ai_categorized_count'] or 0
                manual_categorizations = expenses_stats['manual_categorized_count'] or 0
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–µ—à–±—ç–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å –ª–æ–≥–∏–∫–∞)
                cashback_calculated = 0  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—á–µ—Ç –∫–µ—à–±—ç–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                cashback_transactions = 0
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ (–ø–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞, –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –ª–æ–≥–∞–º–∏)
                errors_encountered = 0
                error_types = {}
                
                # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏ (–∑–∞–≥–ª—É—à–∫–∞)
                total_session_time = 0
                peak_hour = None
                
                # PDF –æ—Ç—á–µ—Ç—ã (–∑–∞–≥–ª—É—à–∫–∞ - –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –ª–æ–≥–∏–∫–æ–π –æ—Ç—á–µ—Ç–æ–≤)
                pdf_reports_generated = 0
                
                # Recurring payments processed (–¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
                recurring_payments_processed = 0
                
                # Budget checks (–∑–∞–≥–ª—É—à–∫–∞)
                budget_checks = 0
                
                # messages_sent ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ä–∞—Å—Ö–æ–¥–æ–≤ (–∑–∞–≥–ª—É—à–∫–∞)
                messages_sent = expenses_stats['count'] or 0
                # voice_messages –∏ photos_sent –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É—é—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
                # (VoiceToTextMiddleware –∏ handle_photo_expense),
                # –ø–æ—ç—Ç–æ–º—É –ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏—Ö –Ω—É–ª—è–º–∏ ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –ë–î
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–º–∞–Ω–¥—ã (–∑–∞–≥–ª—É—à–∫–∞)
                commands_used = {}
                if expenses_stats['count']:
                    commands_used['expense_add'] = expenses_stats['count']
                if incomes_count:
                    commands_used['income_add'] = incomes_count
                
                # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                if existing_analytics:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å
                    existing_analytics.messages_sent = messages_sent
                    # voice_messages –∏ photos_sent –ù–ï —Ç—Ä–æ–≥–∞–µ–º ‚Äî
                    # –æ–Ω–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É—é—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ middleware/handlers
                    existing_analytics.commands_used = commands_used
                    existing_analytics.expenses_added = expenses_stats['count'] or 0
                    existing_analytics.incomes_added = incomes_count
                    existing_analytics.categories_used = categories_used
                    existing_analytics.ai_categorizations = ai_categorizations
                    existing_analytics.manual_categorizations = manual_categorizations
                    existing_analytics.cashback_calculated = cashback_calculated
                    existing_analytics.cashback_transactions = cashback_transactions
                    existing_analytics.errors_encountered = errors_encountered
                    existing_analytics.error_types = error_types
                    existing_analytics.total_session_time = total_session_time
                    existing_analytics.peak_hour = peak_hour
                    existing_analytics.pdf_reports_generated = pdf_reports_generated
                    existing_analytics.recurring_payments_processed = recurring_payments_processed
                    existing_analytics.budget_checks = budget_checks
                    existing_analytics.save()
                    
                    logger.info(f"Updated analytics for user {profile.telegram_id} for {target_date}")
                else:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                    # voice_messages –∏ photos_sent –Ω–µ –ø–µ—Ä–µ–¥–∞—ë–º ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è default=0.
                    # –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å —É–∂–µ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ —á–µ—Ä–µ–∑ increment_analytics_counter,
                    # –æ–Ω–∞ –ø–æ–ø–∞–¥—ë—Ç –≤ existing_analytics –≤—ã—à–µ.
                    UserAnalytics.objects.create(
                        profile=profile,
                        date=target_date,
                        messages_sent=messages_sent,
                        commands_used=commands_used,
                        expenses_added=expenses_stats['count'] or 0,
                        incomes_added=incomes_count,
                        categories_used=categories_used,
                        ai_categorizations=ai_categorizations,
                        manual_categorizations=manual_categorizations,
                        cashback_calculated=cashback_calculated,
                        cashback_transactions=cashback_transactions,
                        errors_encountered=errors_encountered,
                        error_types=error_types,
                        total_session_time=total_session_time,
                        peak_hour=peak_hour,
                        pdf_reports_generated=pdf_reports_generated,
                        recurring_payments_processed=recurring_payments_processed,
                        budget_checks=budget_checks
                    )
                    created_analytics += 1
                    logger.debug(f"Created analytics for user {profile.telegram_id} for {target_date}")
                
                processed_profiles += 1
                
            except Exception as e:
                logger.error(f"Error processing analytics for user {profile.telegram_id}: {e}")
                continue
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (—Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π)
        try:
            old_threshold = timezone.now() - timedelta(days=90)
            deleted_count, _ = UserAnalytics.objects.filter(
                date__lt=old_threshold.date()
            ).delete()
            
            if deleted_count > 0:
                logger.info(f"Deleted {deleted_count} old analytics records")
        
        except Exception as e:
            logger.error(f"Failed to cleanup old analytics: {e}")
        
        logger.info(f"Daily analytics collection completed: {processed_profiles} users processed, {created_analytics} new records created")
        
        return {
            'date': target_date.isoformat(),
            'processed_profiles': processed_profiles,
            'created_analytics': created_analytics,
            'updated_analytics': processed_profiles - created_analytics
        }
    
    except Exception as e:
        logger.error(f"Daily analytics collection failed: {e}", exc_info=True)
        return {'error': str(e)}


@shared_task
def process_recurring_payments():
    """Process recurring payments for today at 12:00"""
    bot = None
    loop = None
    try:
        from bot.services.recurring import process_recurring_payments_for_today
        from bot.utils.expense_messages import format_expense_added_message, format_income_added_message
        from bot.utils import get_text
        from aiogram import Bot
        from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup
        # Use main bot token for user-facing notifications
        bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') or os.getenv('MONITORING_BOT_TOKEN')
        bot = Bot(token=bot_token)
        
        # Run async function in sync context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Process recurring payments
        processed_count, processed_payments = loop.run_until_complete(
            process_recurring_payments_for_today()
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –æ —Å–ø–∏—Å–∞–Ω–Ω—ã—Ö –µ–∂–µ–º–µ—Å—è—á–Ω—ã—Ö –ø–ª–∞—Ç–µ–∂–∞—Ö
        for payment_info in processed_payments:
            try:
                user_id = payment_info['user_id']
                operation = payment_info['operation']
                operation_type = payment_info.get('operation_type')
                payment = payment_info['payment']
                
                # –ü–æ–ª—É—á–∞–µ–º —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è
                from expenses.models import Profile
                profile = Profile.objects.filter(telegram_id=user_id).first()
                user_lang = profile.language_code if profile else 'ru'
                
                cashback_text = ""
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ, –∫–∞–∫ –ø—Ä–∏ —Ä—É—á–Ω–æ–º —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏
                if operation_type == 'income':
                    text = loop.run_until_complete(
                        format_income_added_message(
                            income=operation,
                            category=getattr(operation, 'category', None),
                            is_recurring=True,
                            lang=user_lang
                        )
                    )
                    edit_callback = f"edit_income_{operation.id}"
                else:
                    text = loop.run_until_complete(
                        format_expense_added_message(
                            expense=operation,
                            category=operation.category,
                            cashback_text=cashback_text,
                            is_recurring=True,
                            lang=user_lang
                        )
                    )
                    edit_callback = f"edit_expense_{operation.id}"
                
                keyboard = InlineKeyboardMarkup(inline_keyboard=[
                    [
                        InlineKeyboardButton(
                            text=get_text('edit_button', user_lang),
                            callback_data=edit_callback
                        )
                    ]
                ])
                
                loop.run_until_complete(
                    bot.send_message(
                        chat_id=user_id,
                        text=text,
                        reply_markup=keyboard,
                        parse_mode="HTML"
                    )
                )
                
                logger.info(f"Sent notification to user {user_id} about recurring payment")
                
            except Exception as e:
                logger.error(f"Error sending notification to user {payment_info.get('user_id')}: {e}")
        
        logger.info(f"Processed {processed_count} recurring payments")
        
    except Exception as e:
        logger.error(f"Error in process_recurring_payments task: {e}")

    finally:
        _shutdown_event_loop(loop, bot=bot, label="process_recurring_payments")


@shared_task
def update_keywords_weights(expense_id: int, old_category_id: int, new_category_id: int):
    """
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ—Å–ª–µ —Ä—É—á–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
    –ò–°–ü–û–õ–¨–ó–£–ï–¢ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ö–û–î –∏–∑ keyword_service.py

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ü–û–õ–ù–£–Æ –§–†–ê–ó–£ –∫–∞–∫ keyword (–Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞!)

    –í–ê–ñ–ù–û: –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ - –æ–¥–Ω–æ —Å–ª–æ–≤–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –≤ –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏!
    –ï—Å–ª–∏ —Å–ª–æ–≤–æ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –¥—Ä—É–≥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –æ–Ω–æ –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ –æ—Ç—Ç—É–¥–∞.
    """
    try:
        from expenses.models import Expense, ExpenseCategory
        from bot.utils.keyword_service import normalize_keyword_text, ensure_unique_keyword

        # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç—ã
        expense = Expense.objects.select_related('profile').get(id=expense_id)
        new_category = ExpenseCategory.objects.select_related('profile').get(id=new_category_id)
        old_category = ExpenseCategory.objects.get(id=old_category_id) if old_category_id else None

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º description –∫–∞–∫ –¶–ï–õ–£–Æ –§–†–ê–ó–£
        keyword = normalize_keyword_text(expense.description)

        if not keyword or len(keyword) < 3:
            logger.info(f"Keyword too short after normalization, skipping for expense {expense_id}")
            return

        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∏ —Å–æ–∑–¥–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º keyword
        kw_obj, created, removed = ensure_unique_keyword(
            profile=expense.profile,
            category=new_category,
            word=keyword,
            is_income=False
        )

        if not kw_obj:
            logger.warning(f"Failed to create/update keyword '{keyword}' for expense {expense_id}")
            return

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π (—Ä—É—á–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ = —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª)
        kw_obj.usage_count += 1
        kw_obj.save()

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        old_cat_name = old_category.name if old_category else 'None'
        new_cat_name = new_category.name or new_category.name_ru or new_category.name_en or f'ID:{new_category.id}'

        action = "Created" if created else "Updated"
        logger.info(
            f"{action} keyword '{keyword}' for expense {expense_id}: "
            f"'{old_cat_name}' -> '{new_cat_name}' "
            f"(removed {removed} duplicates, user {expense.profile.telegram_id})"
        )

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö keywords –µ—Å–ª–∏ –∏—Ö —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
        cleanup_old_keywords(profile_id=expense.profile.id, is_income=False)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç 50 —Å–ª–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        check_category_keywords_limit(new_category)
        if old_category:
            check_category_keywords_limit(old_category)

        logger.info(f"Successfully updated keywords weights for expense {expense_id}")

    except Exception as e:
        logger.error(f"Error in update_keywords_weights task: {e}", exc_info=True)


def cleanup_old_keywords(profile_id: int, is_income: bool = False):
    """
    –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –µ—Å–ª–∏ –∏—Ö –±–æ–ª—å—à–µ 1000 —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    –£–¥–∞–ª—è–µ—Ç —Å–∞–º—ã–µ –¥–∞–≤–Ω–æ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å–ª–æ–≤–∞ (–ø–æ –ø–æ–ª—é last_used).

    Args:
        profile_id: ID –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        is_income: True –¥–ª—è –¥–æ—Ö–æ–¥–æ–≤, False –¥–ª—è —Ä–∞—Å—Ö–æ–¥–æ–≤
    """
    try:
        from expenses.models import CategoryKeyword, IncomeCategoryKeyword

        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
        KeywordModel = IncomeCategoryKeyword if is_income else CategoryKeyword

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        total = KeywordModel.objects.filter(
            category__profile_id=profile_id
        ).count()

        if total >= 1000:
            logger.info(f"User {profile_id} has {total} keywords, cleaning up...")

            # –£–¥–∞–ª—è–µ–º 100 —Å–∞–º—ã—Ö –¥–∞–≤–Ω–æ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Å–ª–æ–≤ (–ø–æ last_used, ascending)
            keywords_to_delete = KeywordModel.objects.filter(
                category__profile_id=profile_id
            ).order_by('last_used')[:100].values_list('id', flat=True)

            # –£–¥–∞–ª–∏—Ç—å —Ç–æ–ª—å–∫–æ 100 —Å–∞–º—ã—Ö —Å—Ç–∞—Ä—ã—Ö –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
            deleted = KeywordModel.objects.filter(
                id__in=list(keywords_to_delete)
            ).delete()

            logger.info(f"Deleted {deleted[0]} old keywords for user {profile_id}")

            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            final_total = KeywordModel.objects.filter(
                category__profile_id=profile_id
            ).count()

            logger.info(f"Cleanup complete for user {profile_id}: {total} -> {final_total} keywords")

    except Exception as e:
        logger.error(f"Error in cleanup_old_keywords for user {profile_id}: {e}")


@shared_task
def learn_keywords_on_create(expense_id: int, category_id: int):
    """
    –û–±—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–π —Ç—Ä–∞—Ç—ã —Å AI-–∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–µ–π.
    –ò–°–ü–û–õ–¨–ó–£–ï–¢ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ö–û–î –∏–∑ keyword_service.py

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –û–ß–ò–©–ï–ù–ù–£–Æ –§–†–ê–ó–£ description –∫–∞–∫ –µ–¥–∏–Ω—ã–π keyword:
    - –£–¥–∞–ª—è–µ—Ç stop words (–ø—Ä–µ–¥–ª–æ–≥–∏, –≥–ª–∞–≥–æ–ª—ã, –≤–∞–ª—é—Ç—ã)
    - –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç (lowercase, —É–±–∏—Ä–∞–µ—Ç emoji/–ø—É–Ω–∫—Ç—É–∞—Ü–∏—é)
    - –ï—Å–ª–∏ —Ñ—Ä–∞–∑–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è (>4 —Å–ª–æ–≤) ‚Äî –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç

    –ü—Ä–∏–º–µ—Ä: "–í—á–µ—Ä–∞ –∫—É–ø–∏–ª –∫–æ—Ñ–µ –≤ —Å—Ç–∞—Ä–±–∞–∫—Å–µ 350—Ä" ‚Üí "–∫–æ—Ñ–µ —Å—Ç–∞—Ä–±–∞–∫—Å–µ"
    """
    try:
        from expenses.models import Expense, ExpenseCategory
        from bot.utils.keyword_service import ensure_unique_keyword

        expense = Expense.objects.select_related('profile', 'category').get(id=expense_id)
        category = ExpenseCategory.objects.get(id=category_id)

        if not category:
            return

        # ensure_unique_keyword —Å–∞–º –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏ —É–¥–∞–ª—è–µ—Ç stop words —á–µ—Ä–µ–∑ prepare_keyword_for_save()
        # –ü–µ—Ä–µ–¥–∞—ë–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π description ‚Äî –≤—Å—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏
        kw_obj, created, removed = ensure_unique_keyword(
            profile=expense.profile,
            category=category,
            word=expense.description,  # ‚Üê –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç, –æ—á–∏—Å—Ç–∫–∞ –≤–Ω—É—Ç—Ä–∏
            is_income=False
        )

        if not kw_obj:
            return

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
        if created:
            kw_obj.usage_count = 1
        else:
            kw_obj.usage_count += 1

        kw_obj.save()

        # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –ª–æ–≥–æ–≤
        cat_name = category.name or category.name_ru or category.name_en or f'ID:{category.id}'

        logger.info(
            f"Learned keyword '{kw_obj.keyword}' for expense category '{cat_name}' "
            f"(user {expense.profile.telegram_id}, original: '{expense.description}', removed {removed} duplicates)"
        )

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–∑–¥–∞–ª–∏ –Ω–æ–≤—ã–π
        if created:
            cleanup_old_keywords(profile_id=expense.profile.id, is_income=False)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç 50 —Å–ª–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        check_category_keywords_limit(category)

    except Exception as e:
        logger.error(f"Error in learn_keywords_on_create: {e}")


def extract_words_from_description(description: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è —Ä–∞—Å—Ö–æ–¥–∞"""
    # –£–¥–∞–ª—è–µ–º —á–∏—Å–ª–∞, –≤–∞–ª—é—Ç—É, –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    text = re.sub(r'\d+', '', description)
    # –í–ê–ñ–ù–û: –Ω–µ —É–¥–∞–ª—è–µ–º –±—É–∫–≤—É "—Ä" - –æ–Ω–∞ —á–∞—Å—Ç—å –º–Ω–æ–≥–∏—Ö —Å–ª–æ–≤ (–≥—Ä–µ–Ω–∫–∏, –≥–æ—Ä–æ—Ö –∏ —Ç.–¥.)
    # –í–∞–ª—é—Ç—É "—Ä" —Ñ–∏–ª—å—Ç—Ä—É–µ–º —á–µ—Ä–µ–∑ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    text = re.sub(r'[‚ÇΩ$‚Ç¨¬£¬•\.,"\'!?;:\-\(\)]', ' ', text)

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    words = text.lower().split()

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    stop_words = {
        '–∏', '–≤', '–Ω–∞', '—Å', '–∑–∞', '–ø–æ', '–¥–ª—è', '–æ—Ç', '–¥–æ', '–∏–∑',
        '–∏–ª–∏', '–Ω–æ', '–∞', '–∫', '—É', '–æ', '–æ–±', '–ø–æ–¥', '–Ω–∞–¥',
        '–∫—É–ø–∏–ª', '–∫—É–ø–∏–ª–∞', '–∫—É–ø–∏–ª–∏', '–≤–∑—è–ª', '–≤–∑—è–ª–∞', '–≤–∑—è–ª–∏',
        '–ø–æ—Ç—Ä–∞—Ç–∏–ª', '–ø–æ—Ç—Ä–∞—Ç–∏–ª–∞', '–ø–æ—Ç—Ä–∞—Ç–∏–ª–∏', '–æ–ø–ª–∞—Ç–∏–ª', '–æ–ø–ª–∞—Ç–∏–ª–∞',
        '—Ä—É–±–ª—å', '—Ä—É–±–ª—è', '—Ä—É–±–ª–µ–π', '—Ä—É–±', '—Ä', '—Ç—ã—Å', '—Ç—ã—Å—è—á'
    }

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–æ–≤–∞
    filtered_words = []
    for word in words:
        word = word.strip()
        if word and len(word) >= 3 and word not in stop_words:
            filtered_words.append(word)

    return filtered_words


def filter_keywords_for_saving(words: List[str]) -> List[str]:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º:
    1. –ï—Å–ª–∏ —Å–ª–æ–≤ > 4 ‚Üí –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∏—á–µ–≥–æ (—Å–ø–∏—Å–æ–∫ –ø–æ–∫—É–ø–æ–∫)
    2. –ï—Å–ª–∏ —Å–ª–æ–≤ > 2 –ò –µ—Å—Ç—å –≥–ª–∞–≥–æ–ª ‚Üí —É–¥–∞–ª—è–µ–º –≥–ª–∞–≥–æ–ª—ã –∏ –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 2 —Å–ª–æ–≤–∞
    3. –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö ‚Üí –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 3 —Å–ª–æ–≤–∞

    Args:
        words: –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è

    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î (0-3 —Å–ª–æ–≤–∞)
    """
    # –ü—Ä–∞–≤–∏–ª–æ 1: –ë–æ–ª–µ–µ 4 —Å–ª–æ–≤ ‚Üí —Å–ø–∏—Å–æ–∫ –ø–æ–∫—É–ø–æ–∫, –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    if len(words) > 4:
        logger.debug(f"Too many words ({len(words)} > 4), skipping keyword saving")
        return []

    # –°–ø–∏—Å–æ–∫ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –≥–ª–∞–≥–æ–ª–æ–≤ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
    verbs = {
        # –£–∂–µ –≤ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞—Ö, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –¥—É–±–ª–∏—Ä—É–µ–º
        '–∫—É–ø–∏–ª', '–∫—É–ø–∏–ª–∞', '–∫—É–ø–∏–ª–∏', '–≤–∑—è–ª', '–≤–∑—è–ª–∞', '–≤–∑—è–ª–∏',
        '–ø–æ—Ç—Ä–∞—Ç–∏–ª', '–ø–æ—Ç—Ä–∞—Ç–∏–ª–∞', '–ø–æ—Ç—Ä–∞—Ç–∏–ª–∏', '–æ–ø–ª–∞—Ç–∏–ª', '–æ–ø–ª–∞—Ç–∏–ª–∞', '–æ–ø–ª–∞—Ç–∏–ª–∏',
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥–ª–∞–≥–æ–ª—ã
        '–∑–∞–∫–∞–∑–∞–ª', '–∑–∞–∫–∞–∑–∞–ª–∞', '–∑–∞–∫–∞–∑–∞–ª–∏', '–ø—Ä–∏–æ–±—Ä–µ–ª', '–ø—Ä–∏–æ–±—Ä–µ–ª–∞', '–ø—Ä–∏–æ–±—Ä–µ–ª–∏',
        '–∫—É–ø–∏–ª–∞', '—Å—ä–µ–ª', '—Å—ä–µ–ª–∞', '—Å—ä–µ–ª–∏', '–≤—ã–ø–∏–ª', '–≤—ã–ø–∏–ª–∞', '–≤—ã–ø–∏–ª–∏',
        '—Å—Ö–æ–¥–∏–ª', '—Å—Ö–æ–¥–∏–ª–∞', '—Å—Ö–æ–¥–∏–ª–∏', '–æ—Ç–¥–∞–ª', '–æ—Ç–¥–∞–ª–∞', '–æ—Ç–¥–∞–ª–∏',
        '–∑–∞–ø–ª–∞—Ç–∏–ª', '–∑–∞–ø–ª–∞—Ç–∏–ª–∞', '–∑–∞–ø–ª–∞—Ç–∏–ª–∏', '–≤–Ω–µ—Å', '–≤–Ω–µ—Å–ª–∞', '–≤–Ω–µ—Å–ª–∏',
        '–ø–µ—Ä–µ–≤–µ–ª', '–ø–µ—Ä–µ–≤–µ–ª–∞', '–ø–µ—Ä–µ–≤–µ–ª–∏', '–æ—Ç–ø—Ä–∞–≤–∏–ª', '–æ—Ç–ø—Ä–∞–≤–∏–ª–∞', '–æ—Ç–ø—Ä–∞–≤–∏–ª–∏',
        '–ø–æ–ª–æ–∂–∏–ª', '–ø–æ–ª–æ–∂–∏–ª–∞', '–ø–æ–ª–æ–∂–∏–ª–∏', '—Å–Ω—è–ª', '—Å–Ω—è–ª–∞', '—Å–Ω—è–ª–∏'
    }

    # –ò—â–µ–º –≥–ª–∞–≥–æ–ª—ã –≤ —Å–ø–∏—Å–∫–µ —Å–ª–æ–≤
    words_without_verbs = [word for word in words if word not in verbs]
    has_verbs = len(words_without_verbs) < len(words)

    # –ü—Ä–∞–≤–∏–ª–æ 2: –ë–æ–ª–µ–µ 2 —Å–ª–æ–≤ –ò –µ—Å—Ç—å –≥–ª–∞–≥–æ–ª ‚Üí –±–µ—Ä–µ–º 2 —Å–ª–æ–≤–∞ –±–µ–∑ –≥–ª–∞–≥–æ–ª–∞
    if len(words) > 2 and has_verbs:
        result = words_without_verbs[:2]
        logger.debug(f"Found verbs in {len(words)} words, saving first 2 non-verb words: {result}")
        return result

    # –ü—Ä–∞–≤–∏–ª–æ 3: –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö ‚Üí –º–∞–∫—Å–∏–º—É–º 3 —Å–ª–æ–≤–∞
    result = words[:3]
    logger.debug(f"Saving up to 3 words from {len(words)} total: {result}")
    return result


def check_category_keywords_limit(category):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–º–∞–∫—Å–∏–º—É–º 50)

    –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –¥–ª—è —Ä–∞—Å—Ö–æ–¥–æ–≤ (ExpenseCategory), —Ç–∞–∫ –∏ –¥–ª—è –¥–æ—Ö–æ–¥–æ–≤ (IncomeCategory)
    —á–µ—Ä–µ–∑ duck typing - –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –º–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.
    """
    from expenses.models import CategoryKeyword, IncomeCategoryKeyword, ExpenseCategory, IncomeCategory

    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —á–µ—Ä–µ–∑ duck typing
        if isinstance(category, IncomeCategory):
            KeywordModel = IncomeCategoryKeyword
            category_type = "income"
        elif isinstance(category, ExpenseCategory):
            KeywordModel = CategoryKeyword
            category_type = "expense"
        else:
            logger.warning(f"Unknown category type: {type(category)}")
            return

        keywords = KeywordModel.objects.filter(category=category)

        if keywords.count() > 50:
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ø-50 –ø–æ usage_count
            keywords_list = list(keywords)
            keywords_list.sort(key=lambda k: k.usage_count, reverse=True)

            # –£–¥–∞–ª—è–µ–º —Å–ª–æ–≤–∞ —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
            keywords_to_delete = keywords_list[50:]
            for kw in keywords_to_delete:
                cat_name = category.name or category.name_ru or category.name_en or '(no name)'
                logger.info(f"Deleting {category_type} keyword '{kw.keyword}' from category '{cat_name}' (low usage)")
                kw.delete()

            cat_name = category.name or category.name_ru or category.name_en or '(no name)'
            logger.info(f"Limited {category_type} keywords for category '{cat_name}' to 50 items")

    except Exception as e:
        logger.error(f"Error checking category keywords limit: {e}")


# Backward compatible entry-point that now calls the new task implementation
@shared_task
def process_held_affiliate_commissions():
    from expenses.tasks import process_affiliate_commissions

    logger.warning(
        "process_held_affiliate_commissions is deprecated; routing to expenses.tasks.process_affiliate_commissions"
    )
    return process_affiliate_commissions()


@shared_task
def update_top5_keyboards():
    """–ï–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 05:00 MSK: –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –¢–æ–ø‚Äë5 –∏ –æ–±–Ω–æ–≤–∏—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."""
    bot = None
    loop = None
    try:
        from expenses.models import Profile, Top5Snapshot, Top5Pin
        from bot.services.top5 import (
            calculate_top5_sync, save_snapshot, build_top5_keyboard, get_profiles_with_activity
        )
        from datetime import date
        from calendar import monthrange

        # –ë–æ—Ç –¥–ª—è –≤—ã–∑–æ–≤–∞ editMessageReplyMarkup
        bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') or os.getenv('MONITORING_BOT_TOKEN')
        bot = Bot(token=bot_token)

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # –û–∫–Ω–æ: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ (rolling)
        today = date.today()
        from datetime import timedelta
        window_end = today
        window_start = today - timedelta(days=89)

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é
        profiles = loop.run_until_complete(get_profiles_with_activity(window_start, window_end))

        updated = 0
        for profile in profiles:
            try:
                items, digest = loop.run_until_complete(calculate_top5_sync(profile, window_start, window_end))
                snap = Top5Snapshot.objects.filter(profile=profile).first()
                if not snap or snap.hash != digest or snap.window_start != window_start or snap.window_end != window_end:
                    loop.run_until_complete(
                        save_snapshot(profile, window_start, window_end, items, digest)
                    )
                # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –∑–Ω–∞–µ–º ids
                pin = Top5Pin.objects.filter(profile=profile).first()
                if pin:
                    try:
                        kb: InlineKeyboardMarkup = build_top5_keyboard(items)
                        loop.run_until_complete(
                            bot.edit_message_reply_markup(chat_id=pin.chat_id, message_id=pin.message_id, reply_markup=kb)
                        )
                        updated += 1

                    except (TelegramBadRequest, TelegramNotFound) as e:
                        # Telegram-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏
                        error_text = str(e).lower()

                        # –°–æ–æ–±—â–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                        if any(msg in error_text for msg in [
                            "message to edit not found",
                            "message not found",
                            "message to delete not found"
                        ]):
                            logger.info(
                                f"Top-5 pin removed for user {profile.telegram_id}: "
                                f"message {pin.message_id} not found (probably deleted by user)"
                            )
                            try:
                                pin.delete()
                            except Exception as delete_err:
                                logger.error(
                                    f"Failed to delete Top-5 pin for user {profile.telegram_id}: {delete_err}",
                                    exc_info=True
                                )
                        else:
                            # –î—Ä—É–≥–∏–µ TelegramBadRequest (–Ω–∞–ø—Ä–∏–º–µ—Ä, invalid chat_id)
                            logger.warning(
                                f"Top-5 Telegram error for user {profile.telegram_id}: {e}"
                            )

                    except Exception as e:
                        # –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ (—Å–µ—Ç—å, –ë–î, Python)
                        logger.error(
                            f"Top-5 unexpected error for user {profile.telegram_id}: {e}",
                            exc_info=True
                        )
            except Exception as user_err:
                logger.error(f"Top-5 update error for user {profile.telegram_id}: {user_err}")
                continue
        logger.info(f"Top-5 updated for {updated} pinned messages (profiles processed: {len(profiles)})")
    except Exception as e:
        logger.error(f"Error in update_top5_keyboards: {e}")

    finally:
        _shutdown_event_loop(loop, bot=bot, label="update_top5_keyboards")


# ==================== INCOME KEYWORDS LEARNING ====================
# –ó–∞–¥–∞—á–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–æ—Ö–æ–¥–æ–≤ (–∞–Ω–∞–ª–æ–≥ —Ä–∞—Å—Ö–æ–¥–æ–≤)


@shared_task
def update_income_keywords(income_id: int, old_category_id: int, new_category_id: int):
    """
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ—Å–ª–µ —Ä—É—á–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–æ—Ö–æ–¥–∞.
    –ò–°–ü–û–õ–¨–ó–£–ï–¢ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ö–û–î –∏–∑ keyword_service.py

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –û–ß–ò–©–ï–ù–ù–£–Æ –§–†–ê–ó–£ description –∫–∞–∫ –µ–¥–∏–Ω—ã–π keyword:
    - –£–¥–∞–ª—è–µ—Ç stop words (–ø—Ä–µ–¥–ª–æ–≥–∏, –≥–ª–∞–≥–æ–ª—ã, –≤–∞–ª—é—Ç—ã)
    - –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç (lowercase, —É–±–∏—Ä–∞–µ—Ç emoji/–ø—É–Ω–∫—Ç—É–∞—Ü–∏—é)
    - –ï—Å–ª–∏ —Ñ—Ä–∞–∑–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è (>4 —Å–ª–æ–≤) ‚Äî –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç

    –ü—Ä–∏–º–µ—Ä: "–ü–æ–ª—É—á–∏–ª –∑–∞—Ä–ø–ª–∞—Ç—É –∑–∞ –¥–µ–∫–∞–±—Ä—å 50000—Ä" ‚Üí "–∑–∞—Ä–ø–ª–∞—Ç—É –¥–µ–∫–∞–±—Ä—å"
    """
    try:
        from expenses.models import Income, IncomeCategory
        from bot.utils.keyword_service import ensure_unique_keyword

        # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç—ã
        income = Income.objects.select_related('profile').get(id=income_id)
        new_category = IncomeCategory.objects.select_related('profile').get(id=new_category_id)
        old_category = IncomeCategory.objects.get(id=old_category_id) if old_category_id else None

        # ensure_unique_keyword —Å–∞–º –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏ —É–¥–∞–ª—è–µ—Ç stop words —á–µ—Ä–µ–∑ prepare_keyword_for_save()
        kw_obj, created, removed = ensure_unique_keyword(
            profile=income.profile,
            category=new_category,
            word=income.description,  # ‚Üê –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç, –æ—á–∏—Å—Ç–∫–∞ –≤–Ω—É—Ç—Ä–∏
            is_income=True
        )

        if not kw_obj:
            logger.info(f"Could not create/find keyword for income {income_id}")
            return

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π
        kw_obj.usage_count += 1
        kw_obj.save()

        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Ç–æ–≥–∏
        old_cat_name = old_category.name if old_category else 'None'
        new_cat_name = new_category.name or new_category.name_ru or new_category.name_en or f'ID:{new_category.id}'

        # kw_obj —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—á–∏—â–µ–Ω–Ω—É—é —Ñ—Ä–∞–∑—É
        saved_keyword = getattr(kw_obj, 'keyword', income.description)
        logger.info(
            f"[CELERY] Updated income keyword '{saved_keyword}' from '{old_cat_name}' to '{new_cat_name}' "
            f"(removed {removed} duplicates, user {income.profile.telegram_id})"
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç 50 —Å–ª–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é (–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é)
        check_category_keywords_limit(new_category)
        if old_category:
            check_category_keywords_limit(old_category)

        logger.info(f"Successfully updated income keywords for income {income_id}")

    except Exception as e:
        logger.error(f"Error in update_income_keywords task: {e}")


@shared_task(name='prefetch_cbrf_rates')
def prefetch_cbrf_rates():
    """
    –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∫—É—Ä—Å–æ–≤ –¶–ë –†–§.
    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ 23:30 –ú–°–ö –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π event loop –∏ —Å–≤–µ–∂–∏–π —ç–∫–∑–µ–º–ø–ª—è—Ä CurrencyConverter,
    —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã "Event loop is closed" –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
    singleton-—Å–µ—Å—Å–∏–∏ –∏–∑ –¥—Ä—É–≥–æ–≥–æ (—É–∂–µ –∑–∞–∫—Ä—ã—Ç–æ–≥–æ) event loop.
    """
    import asyncio
    from bot.services.currency_conversion import CurrencyConverter

    async def _prefetch() -> int:
        converter = CurrencyConverter()
        try:
            rates = await converter.fetch_daily_rates()
            if rates:
                logger.info(f"CBRF: Prefetched {len(rates)} rates")
                return len(rates)
            else:
                logger.error("CBRF: Failed to prefetch rates")
                return 0
        finally:
            if converter.session and not converter.session.closed:
                await converter.session.close()

    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        count = loop.run_until_complete(_prefetch())
    finally:
        _shutdown_event_loop(loop, label="prefetch_cbrf_rates")
    return f"Prefetched {count} CBRF rates"


@shared_task
def learn_income_keywords_on_create(income_id: int):
    """
    –û–±—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ –¥–æ—Ö–æ–¥–∞ —Å AI-–∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–µ–π.
    –ò–°–ü–û–õ–¨–ó–£–ï–¢ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ö–û–î –∏–∑ keyword_service.py

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –û–ß–ò–©–ï–ù–ù–£–Æ –§–†–ê–ó–£ description –∫–∞–∫ –µ–¥–∏–Ω—ã–π keyword:
    - –£–¥–∞–ª—è–µ—Ç stop words (–ø—Ä–µ–¥–ª–æ–≥–∏, –≥–ª–∞–≥–æ–ª—ã, –≤–∞–ª—é—Ç—ã)
    - –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç (lowercase, —É–±–∏—Ä–∞–µ—Ç emoji/–ø—É–Ω–∫—Ç—É–∞—Ü–∏—é)
    - –ï—Å–ª–∏ —Ñ—Ä–∞–∑–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è (>4 —Å–ª–æ–≤) ‚Äî –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç

    –ü—Ä–∏–º–µ—Ä: "–ü–æ–ª—É—á–∏–ª –∑–∞—Ä–ø–ª–∞—Ç—É –∑–∞ –¥–µ–∫–∞–±—Ä—å 50000—Ä" ‚Üí "–∑–∞—Ä–ø–ª–∞—Ç—É –¥–µ–∫–∞–±—Ä—å"
    """
    try:
        from expenses.models import Income
        from bot.utils.keyword_service import ensure_unique_keyword

        income = Income.objects.select_related('profile', 'category').get(id=income_id)

        if not income.ai_categorized or not income.category:
            return

        category = income.category

        # ensure_unique_keyword —Å–∞–º –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏ —É–¥–∞–ª—è–µ—Ç stop words —á–µ—Ä–µ–∑ prepare_keyword_for_save()
        kw_obj, created, removed = ensure_unique_keyword(
            profile=income.profile,
            category=category,
            word=income.description,  # ‚Üê –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç, –æ—á–∏—Å—Ç–∫–∞ –≤–Ω—É—Ç—Ä–∏
            is_income=True
        )

        if not kw_obj:
            return

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
        if created:
            kw_obj.usage_count = 1
        else:
            kw_obj.usage_count += 1

        kw_obj.save()

        # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –ª–æ–≥–æ–≤
        cat_name = category.name or category.name_ru or category.name_en or f'ID:{category.id}'

        # kw_obj ‚Äî —ç—Ç–æ IncomeKeyword, –∞—Ç—Ä–∏–±—É—Ç keyword —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—á–∏—â–µ–Ω–Ω—É—é —Ñ—Ä–∞–∑—É
        saved_keyword = getattr(kw_obj, 'keyword', income.description)
        logger.info(
            f"Learned keyword '{saved_keyword}' for income category '{cat_name}' "
            f"(user {income.profile.telegram_id}, removed {removed} duplicates)"
        )

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–∑–¥–∞–ª–∏ –Ω–æ–≤—ã–π
        if created:
            cleanup_old_keywords(profile_id=income.profile.id, is_income=True)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç 50 —Å–ª–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        check_category_keywords_limit(category)

    except Exception as e:
        logger.error(f"Error in learn_income_keywords_on_create: {e}")


# ---------------------------------------------------------------------------
# Cross-server monitoring: expense_bot checks nutrition_bot availability
# ---------------------------------------------------------------------------

REMOTE_SERVER_NAME = "Nutrition Bot"
REMOTE_SERVER_IP = "45.93.201.222"
REMOTE_HEALTH_URL = "https://showmefood.duckdns.org/health/"
REMOTE_CHECK_TIMEOUT = 15  # seconds
REMOTE_FAILURES_BEFORE_ALERT = 1  # alert on first failure

CACHE_KEY_REMOTE_FAILURES = "remote_server:failures"
CACHE_KEY_REMOTE_ALERT_SENT = "remote_server:alert_sent"
CACHE_KEY_REMOTE_DOWN_SINCE = "remote_server:down_since"


@shared_task
def check_remote_server_health():
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ (Nutrition Bot).
    –ï—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω REMOTE_FAILURES_BEFORE_ALERT —Ä–∞–∑ –ø–æ–¥—Ä—è–¥ ‚Äî —à–ª—ë—Ç –∞–ª–µ—Ä—Ç.
    –ü—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ ‚Äî —É–≤–µ–¥–æ–º–ª—è–µ—Ç –æ recovery —Å –≤—Ä–µ–º–µ–Ω–µ–º –ø—Ä–æ—Å—Ç–æ—è.
    """
    import requests as http_requests
    from django.core.cache import cache

    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
    is_up = False
    error_detail = ""
    try:
        resp = http_requests.get(REMOTE_HEALTH_URL, timeout=REMOTE_CHECK_TIMEOUT)
        is_up = resp.status_code == 200
        if not is_up:
            error_detail = f"HTTP {resp.status_code}"
    except http_requests.exceptions.Timeout:
        error_detail = "Timeout"
    except http_requests.exceptions.ConnectionError:
        error_detail = "Connection refused"
    except Exception as e:
        error_detail = str(e)[:100]

    # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if is_up:
        _handle_remote_server_up(cache)
    else:
        _handle_remote_server_down(cache, error_detail)


def _handle_remote_server_up(cache) -> None:
    """–°–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫, —à–ª—ë–º recovery –µ—Å–ª–∏ –±—ã–ª –∞–ª–µ—Ä—Ç."""
    was_alert_sent = cache.get(CACHE_KEY_REMOTE_ALERT_SENT)

    if was_alert_sent:
        # –°—á–∏—Ç–∞–µ–º –≤—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è
        down_since_iso = cache.get(CACHE_KEY_REMOTE_DOWN_SINCE)
        downtime_str = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        if down_since_iso:
            try:
                down_since = datetime.fromisoformat(down_since_iso)
                delta = datetime.now() - down_since
                minutes = int(delta.total_seconds() // 60)
                downtime_str = f"~{minutes} –º–∏–Ω" if minutes > 0 else "<1 –º–∏–Ω"
            except (ValueError, TypeError):
                pass

        recovery_sent = _send_remote_alert(
            f"‚úÖ –°–ï–†–í–ï–† –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù\n\n"
            f"–°–µ—Ä–≤–µ—Ä: {REMOTE_SERVER_NAME} ({REMOTE_SERVER_IP})\n"
            f"–í—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è: {downtime_str}"
        )
        if recovery_sent:
            cache.delete(CACHE_KEY_REMOTE_ALERT_SENT)
            cache.delete(CACHE_KEY_REMOTE_DOWN_SINCE)
            logger.info(f"[REMOTE_MONITOR] {REMOTE_SERVER_NAME} recovered, downtime={downtime_str}")
        else:
            logger.warning(f"[REMOTE_MONITOR] Recovery message failed to send, keeping alert flag")

    cache.set(CACHE_KEY_REMOTE_FAILURES, 0, 3600)


def _handle_remote_server_down(cache, error_detail: str) -> None:
    """–°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫, —à–ª—ë–º –∞–ª–µ—Ä—Ç –µ—Å–ª–∏ –ø–æ—Ä–æ–≥ –ø—Ä–µ–≤—ã—à–µ–Ω."""
    failures = (cache.get(CACHE_KEY_REMOTE_FAILURES) or 0) + 1
    cache.set(CACHE_KEY_REMOTE_FAILURES, failures, 3600)

    # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –º–æ–º–µ–Ω—Ç –Ω–∞—á–∞–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
    if failures == 1:
        cache.set(CACHE_KEY_REMOTE_DOWN_SINCE, datetime.now().isoformat(), 86400)

    logger.warning(
        f"[REMOTE_MONITOR] {REMOTE_SERVER_NAME} unreachable "
        f"(attempt {failures}, error: {error_detail})"
    )

    if failures >= REMOTE_FAILURES_BEFORE_ALERT and not cache.get(CACHE_KEY_REMOTE_ALERT_SENT):
        import pytz
        moscow_tz = pytz.timezone('Europe/Moscow')
        now_msk = datetime.now(moscow_tz).strftime('%H:%M')

        sent = _send_remote_alert(
            f"üö® –°–ï–†–í–ï–† –ù–ï–î–û–°–¢–£–ü–ï–ù\n\n"
            f"–°–µ—Ä–≤–µ—Ä: {REMOTE_SERVER_NAME} ({REMOTE_SERVER_IP})\n"
            f"URL: {REMOTE_HEALTH_URL}\n"
            f"–ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω —Å: {now_msk} MSK\n"
            f"–ü—Ä–æ–≤–µ—Ä–æ–∫ –ø–æ–¥—Ä—è–¥: {failures}\n"
            f"–û—à–∏–±–∫–∞: {error_detail}\n\n"
            f"–ü—Ä–æ–≤–µ—Ä—å —Å–µ—Ä–≤–µ—Ä!"
        )
        if sent:
            cache.set(CACHE_KEY_REMOTE_ALERT_SENT, True, 86400)
            logger.error(f"[REMOTE_MONITOR] Alert sent: {REMOTE_SERVER_NAME} is DOWN")
        else:
            logger.error(f"[REMOTE_MONITOR] Failed to send alert, will retry next check")


def _send_remote_alert(message: str) -> bool:
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É —á–µ—Ä–µ–∑ async admin_notifier. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ."""
    try:
        from bot.services.admin_notifier import send_admin_alert
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(send_admin_alert(message))
        finally:
            _shutdown_event_loop(loop, label="check_remote_server_health")
        return bool(result)
    except Exception as e:
        logger.error(f"[REMOTE_MONITOR] Failed to send alert: {e}")
        return False
