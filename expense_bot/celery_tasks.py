from celery import shared_task
from datetime import datetime, date, timedelta, time
import asyncio
import logging
import re
import os
from typing import List

from django.conf import settings
from django.db.models import Count, Sum, Q, Avg, Case, When, FloatField
from django.utils import timezone
from aiogram import Bot
from aiogram.types import InlineKeyboardMarkup

logger = logging.getLogger(__name__)



@shared_task
def send_monthly_reports():
    """Send monthly expense reports to all users on the last day at 20:00"""
    try:
        from expenses.models import Profile, Expense
        from bot.services.notifications import NotificationService
        from calendar import monthrange
        # Use main bot token for user-facing notifications
        bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') or os.getenv('MONITORING_BOT_TOKEN')
        bot = Bot(token=bot_token)
        service = NotificationService(bot)
        
        # Check if today is the last day of month and time is 20:00
        today = datetime.now()
        last_day = monthrange(today.year, today.month)[1]
        
        if today.day != last_day:
            logger.info(f"Not the last day of month ({today.day}/{last_day}), skipping monthly reports")
            return
        
        if today.hour != 20:
            logger.info(f"Not 20:00 ({today.hour}:00), skipping monthly reports")
            return
        
        # Get all active profiles who have expenses this month
        month_start = today.replace(day=1)
        profiles_with_expenses = Expense.objects.filter(
            expense_date__gte=month_start,
            expense_date__lte=today
        ).values_list('profile_id', flat=True).distinct()
        
        profiles = Profile.objects.filter(
            id__in=profiles_with_expenses
        )
        
        logger.info(f"Sending monthly reports to {profiles.count()} users with expenses")
        
        # Run async function in sync context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        for profile in profiles:
            try:
                loop.run_until_complete(
                    service.send_monthly_report(profile.telegram_id, profile)
                )
                logger.info(f"Monthly report sent to user {profile.telegram_id}")
            except Exception as e:
                logger.error(f"Error sending monthly report to user {profile.telegram_id}: {e}")
        
        loop.close()
        
    except Exception as e:
        logger.error(f"Error in send_monthly_reports task: {e}")


@shared_task
def check_budget_limits():
    """Check budget limits and send warnings"""
    try:
        from expenses.models import Profile, Budget, Expense
        from bot.services.notifications import NotificationService
        from decimal import Decimal
        # Use main bot token for user-facing notifications
        bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') or os.getenv('MONITORING_BOT_TOKEN')
        bot = Bot(token=bot_token)
        service = NotificationService(bot)
        
        # Get all active budgets
        budgets = Budget.objects.filter(
            is_active=True
        ).select_related('profile', 'category')
        
        today = date.today()
        
        for budget in budgets:
            try:
                # Calculate spent amount based on period
                if budget.period == 'daily':
                    expenses = Expense.objects.filter(
                        profile=budget.profile,
                        date=today
                    )
                elif budget.period == 'weekly':
                    from datetime import timedelta
                    week_start = today - timedelta(days=today.weekday())
                    expenses = Expense.objects.filter(
                        profile=budget.profile,
                        date__gte=week_start,
                        date__lte=today
                    )
                elif budget.period == 'monthly':
                    month_start = today.replace(day=1)
                    expenses = Expense.objects.filter(
                        profile=budget.profile,
                        date__gte=month_start,
                        date__lte=today
                    )
                else:
                    continue
                
                # Filter by category if specified
                if budget.category:
                    expenses = expenses.filter(category=budget.category)
                
                # Calculate total spent
                spent = sum(e.amount for e in expenses)
                percent = (spent / budget.amount) * 100 if budget.amount > 0 else 0
                
                # Send warnings at 80%, 90%, and 100%
                if percent >= 80:
                    # Check if we should send notification
                    should_notify = False
                    
                    if percent >= 100 and not budget.notified_exceeded:
                        should_notify = True
                        budget.notified_exceeded = True
                    elif 90 <= percent < 100 and not budget.notified_90_percent:
                        should_notify = True
                        budget.notified_90_percent = True
                    elif 80 <= percent < 90 and not budget.notified_80_percent:
                        should_notify = True
                        budget.notified_80_percent = True
                    
                    if should_notify:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        
                        loop.run_until_complete(
                            service.send_budget_warning(
                                budget.profile.telegram_id,
                                budget,
                                spent,
                                percent
                            )
                        )
                        
                        loop.close()
                        budget.save()
                
                # Reset notifications for new period
                elif percent < 80:
                    if budget.notified_80_percent or budget.notified_90_percent or budget.notified_exceeded:
                        budget.notified_80_percent = False
                        budget.notified_90_percent = False
                        budget.notified_exceeded = False
                        budget.save()
                
            except Exception as e:
                logger.error(f"Error checking budget {budget.id}: {e}")
        
    except Exception as e:
        logger.error(f"Error in check_budget_limits task: {e}")


@shared_task
def cleanup_old_expenses():
    """Clean up expenses older than retention period"""
    try:
        from expenses.models import Expense
        from datetime import timedelta
        
        # Keep expenses for 2 years by default
        retention_days = getattr(settings, 'EXPENSE_RETENTION_DAYS', 730)
        cutoff_date = date.today() - timedelta(days=retention_days)
        
        # Delete old expenses
        deleted_count, _ = Expense.objects.filter(
            created_at__lt=cutoff_date
        ).delete()
        
        logger.info(f"Deleted {deleted_count} expenses older than {cutoff_date}")
        
    except Exception as e:
        logger.error(f"Error in cleanup_old_expenses task: {e}")


@shared_task
def send_daily_admin_report():
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    try:
        from expenses.models import (
            Profile, Expense, ExpenseCategory, Subscription, Income,
            UserAnalytics, AIServiceMetrics, SystemHealthCheck, 
            AffiliateCommission, RecurringPayment
        )
        from bot.services.admin_notifier import send_admin_alert, escape_markdown_v2
        from django.utils import timezone
        from django.db.models import Q, Avg, Max, Min
        from datetime import timedelta
        import json

        def esc(v) -> str:
            return escape_markdown_v2(str(v))

        yesterday = timezone.now().date() - timedelta(days=1)
        today = timezone.now().date()
        week_ago = yesterday - timedelta(days=7)
        yesterday_start = timezone.make_aware(datetime.combine(yesterday, datetime.min.time()))
        yesterday_end = timezone.make_aware(datetime.combine(yesterday, datetime.max.time()))

        # ===============================
        # –ë–ê–ó–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô
        # ===============================
        total_users = Profile.objects.count()
        active_users = Expense.objects.filter(
            expense_date=yesterday
        ).values('profile').distinct().count()

        new_users = Profile.objects.filter(
            created_at__date=yesterday
        ).count()

        # WAU (Weekly Active Users) - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –∑–∞ –Ω–µ–¥–µ–ª—é
        weekly_active_users = Expense.objects.filter(
            expense_date__gte=week_ago,
            expense_date__lte=yesterday
        ).values('profile').distinct().count()

        # Retention: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏, –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–µ–¥–µ–ª—é –Ω–∞–∑–∞–¥ –∏ –∞–∫—Ç–∏–≤–Ω—ã–µ –≤—á–µ—Ä–∞
        week_ago_users = Profile.objects.filter(created_at__date=week_ago).values_list('id', flat=True)
        retained_users = Expense.objects.filter(
            profile_id__in=week_ago_users,
            expense_date=yesterday
        ).values('profile').distinct().count()
        retention_rate = (retained_users / len(week_ago_users) * 100) if week_ago_users else 0

        # ===============================
        # –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–°–•–û–î–û–í –ò –î–û–•–û–î–û–í
        # ===============================
        expenses_stats = Expense.objects.filter(
            expense_date=yesterday
        ).aggregate(
            total=Sum('amount'),
            count=Count('id'),
            avg=Avg('amount'),
            max_expense=Max('amount'),
            ai_categorized=Count('id', filter=Q(ai_categorized=True))
        )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ—Ö–æ–¥–∞–º
        incomes_stats = Income.objects.filter(
            income_date=yesterday
        ).aggregate(
            total=Sum('amount'),
            count=Count('id'),
            avg=Avg('amount')
        )

        # AI –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        ai_accuracy_rate = 0
        if expenses_stats['count'] and expenses_stats['count'] > 0:
            ai_accuracy_rate = (expenses_stats['ai_categorized'] / expenses_stats['count']) * 100

        # ===============================
        # –ü–û–î–ü–ò–°–ö–ò –ò –§–ò–ù–ê–ù–°–´
        # ===============================
        new_subscriptions = Subscription.objects.filter(
            created_at__date=yesterday,
            payment_method__in=['stars', 'referral', 'promo']
        ).values('type').annotate(
            count=Count('id')
        ).order_by('type')

        # –ü–æ–¥—Å—á–µ—Ç –ø–æ–¥–ø–∏—Å–æ–∫ –ø–æ —Ç–∏–ø–∞–º
        subs_month = 0
        subs_six_months = 0
        subscription_revenue = 0
        
        for sub in new_subscriptions:
            if sub['type'] == 'month':
                subs_month = sub['count']
                subscription_revenue += sub['count'] * 150  # 150 –∑–≤–µ–∑–¥ –∑–∞ –º–µ—Å—è—á–Ω—É—é
            elif sub['type'] == 'six_months':
                subs_six_months = sub['count']
                subscription_revenue += sub['count'] * 750  # 750 –∑–≤–µ–∑–¥ –∑–∞ –ø–æ–ª—É–≥–æ–¥–æ–≤—É—é

        active_subscriptions = Subscription.objects.filter(
            is_active=True,
            end_date__gt=timezone.now()
        ).count()

        # –ü–æ–¥–ø–∏—Å–∫–∏ –∏—Å—Ç–µ–∫–∞—é—â–∏–µ –≤ –±–ª–∏–∂–∞–π—à–∏–µ 3 –¥–Ω—è
        expiring_soon = Subscription.objects.filter(
            is_active=True,
            end_date__lte=timezone.now() + timedelta(days=3),
            end_date__gt=timezone.now()
        ).count()

        # ===============================
        # –†–ï–§–ï–†–ê–õ–¨–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê
        # ===============================
        affiliate_stats = AffiliateCommission.objects.filter(
            created_at__date=yesterday
        ).aggregate(
            new_commissions=Count('id'),
            total_commission_amount=Sum('commission_amount'),
            paid_commissions=Count('id', filter=Q(status='paid')),
            hold_commissions=Count('id', filter=Q(status='hold'))
        )

        # ===============================
        # AI –°–ï–†–í–ò–°–´ –ú–û–ù–ò–¢–û–†–ò–ù–ì
        # ===============================
        ai_metrics = AIServiceMetrics.objects.filter(
            timestamp__gte=yesterday_start,
            timestamp__lte=yesterday_end
        ).aggregate(
            total_requests=Count('id'),
            successful_requests=Count('id', filter=Q(success=True)),
            avg_response_time=Avg('response_time'),
            max_response_time=Max('response_time'),
            total_tokens=Sum('tokens_used'),
            total_cost=Sum('estimated_cost')
        )

        ai_success_rate = 0
        if ai_metrics['total_requests']:
            ai_success_rate = (ai_metrics['successful_requests'] / ai_metrics['total_requests']) * 100

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–µ—Ä–≤–∏—Å–∞–º
        openai_stats = AIServiceMetrics.objects.filter(
            timestamp__gte=yesterday_start,
            timestamp__lte=yesterday_end,
            service='openai'
        ).aggregate(
            requests=Count('id'),
            avg_time=Avg('response_time'),
            success_rate=Avg(Case(
                When(success=True, then=1.0),
                When(success=False, then=0.0),
                output_field=FloatField()
            ))
        )

        google_stats = AIServiceMetrics.objects.filter(
            timestamp__gte=yesterday_start,
            timestamp__lte=yesterday_end,
            service='google'
        ).aggregate(
            requests=Count('id'),
            avg_time=Avg('response_time'),
            success_rate=Avg(Case(
                When(success=True, then=1.0),
                When(success=False, then=0.0),
                output_field=FloatField()
            ))
        )

        # ===============================
        # –°–ò–°–¢–ï–ú–ê –ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨
        # ===============================
        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã
        latest_health_check = SystemHealthCheck.objects.filter(
            timestamp__gte=yesterday_start
        ).order_by('-timestamp').first()

        system_status = "‚ùì –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        if latest_health_check:
            status_emoji = {
                'healthy': '‚úÖ',
                'degraded': '‚ö†Ô∏è',
                'unhealthy': 'üö®'
            }
            system_status = f"{status_emoji.get(latest_health_check.overall_status, '‚ùì')} {latest_health_check.overall_status.title()}"

        # ===============================
        # –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨–°–ö–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê
        # ===============================
        user_analytics = UserAnalytics.objects.filter(
            date=yesterday
        ).aggregate(
            total_messages=Sum('messages_sent'),
            total_voice_messages=Sum('voice_messages'),
            total_photos=Sum('photos_sent'),
            total_expenses_added=Sum('expenses_added'),
            total_incomes_added=Sum('incomes_added'),
            total_errors=Sum('errors_encountered'),
            total_pdf_reports=Sum('pdf_reports_generated'),
            total_cashback_calculated=Sum('cashback_calculated'),
            active_users_analytics=Count('profile', distinct=True)
        )

        # ===============================
        # –†–ï–ì–£–õ–Ø–†–ù–´–ï –ü–õ–ê–¢–ï–ñ–ò
        # ===============================
        recurring_payments_processed = RecurringPayment.objects.filter(
            last_processed=yesterday
        ).count()

        # ===============================
        # –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –û–¢–ß–ï–¢–ê
        # ===============================
        count_formatted = f"{(expenses_stats['count'] or 0):,}"
        total_formatted = f"{(expenses_stats['total'] or 0):,.0f}"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ç–æ—á–µ–∫
        date_formatted = yesterday.strftime('%d.%m.%Y').replace('.', '\\.')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = (
            f"üìä \*–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç ExpenseBot\*\n"
            f"üìÖ –ó–∞ {date_formatted}\n\n"
            
            f"üë• \*–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:\*\n"
            f"  ‚Ä¢ –í—Å–µ–≥–æ: {esc(f'{total_users:,}')}\n"
            f"  ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –≤—á–µ—Ä–∞: {esc(active_users)}\n"
            f"  ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞ –Ω–µ–¥–µ–ª—é: {esc(weekly_active_users)}\n"
            f"  ‚Ä¢ –ù–æ–≤—ã—Ö —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–π: {esc(new_users)}\n"
            f"  ‚Ä¢ Retention \\(7d\\): {esc(f'{retention_rate:.1f}%')}\n\n"
            
            f"‚≠ê \*–ü–æ–¥–ø–∏—Å–∫–∏:\*\n"
            f"  ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –≤—Å–µ–≥–æ: {esc(active_subscriptions)}\n"
            f"  ‚Ä¢ –ò—Å—Ç–µ–∫–∞—é—Ç –≤ 3 –¥–Ω—è: {esc(expiring_soon)}\n"
            f"  ‚Ä¢ –ö—É–ø–ª–µ–Ω–æ –≤—á–µ—Ä–∞ \\(1 –º–µ—Å\\.\\): {esc(subs_month)}\n"
            f"  ‚Ä¢ –ö—É–ø–ª–µ–Ω–æ –≤—á–µ—Ä–∞ \\(6 –º–µ—Å\\.\\): {esc(subs_six_months)}\n"
        )
        
        if subscription_revenue > 0:
            report += f"  ‚Ä¢ –î–æ—Ö–æ–¥ —Å –ø–æ–¥–ø–∏—Å–æ–∫: {esc(subscription_revenue)} ‚≠ê\n"

        # –†–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞
        if affiliate_stats['new_commissions']:
            report += (
                f"\nüíº \*–†–µ—Ñ–µ—Ä–∞–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞:\*\n"
                f"  ‚Ä¢ –ù–æ–≤—ã—Ö –∫–æ–º–∏—Å—Å–∏–π: {esc(affiliate_stats['new_commissions'])}\n"
                f"  ‚Ä¢ –°—É–º–º–∞ –∫–æ–º–∏—Å—Å–∏–π: {esc(affiliate_stats['total_commission_amount'] or 0)} ‚≠ê\n"
                f"  ‚Ä¢ –ù–∞ —Ö–æ–ª–¥–µ: {esc(affiliate_stats['hold_commissions'])}\n"
            )

        # AI —Å–µ—Ä–≤–∏—Å—ã
        if ai_metrics['total_requests']:
            avg_resp_time = ai_metrics.get('avg_response_time', 0) or 0
            total_tokens = ai_metrics.get('total_tokens', 0) or 0
            report += (
                f"\nü§ñ \*AI —Å–µ—Ä–≤–∏—Å—ã:\*\n"
                f"  ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {esc(ai_metrics['total_requests'])}\n"
                f"  ‚Ä¢ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {esc(f'{ai_success_rate:.1f}%')}\n"
                f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {esc(f'{avg_resp_time:.2f}')}—Å\n"
                f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {esc(f'{total_tokens:,}')}\n"
            )
            
            if ai_metrics.get('total_cost'):
                total_cost = ai_metrics.get('total_cost', 0) or 0
                report += f"  ‚Ä¢ –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${esc(f'{total_cost:.3f}')}\n"
                
            if openai_stats['requests'] and google_stats['requests']:
                openai_success = openai_stats.get('success_rate', 0) * 100
                google_success = google_stats.get('success_rate', 0) * 100
                report += (
                    f"  ‚Ä¢ OpenAI: {esc(openai_stats['requests'])} –∑–∞–ø\\., "
                    f"{esc(f'{openai_success:.0f}')}% —É—Å–ø–µ—Ö\n"
                    f"  ‚Ä¢ Google: {esc(google_stats['requests'])} –∑–∞–ø\\., "
                    f"{esc(f'{google_success:.0f}')}% —É—Å–ø–µ—Ö\n"
                )

        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        if user_analytics['active_users_analytics']:
            report += (
                f"\nüìà \*–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:\*\n"
                f"  ‚Ä¢ –°–æ–æ–±—â–µ–Ω–∏–π: {esc(user_analytics['total_messages'] or 0)}\n"
                f"  ‚Ä¢ –ì–æ–ª–æ—Å–æ–≤—ã—Ö: {esc(user_analytics['total_voice_messages'] or 0)}\n"
                f"  ‚Ä¢ –§–æ—Ç–æ: {esc(user_analytics['total_photos'] or 0)}\n"
                f"  ‚Ä¢ AI –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è: {esc(f'{ai_accuracy_rate:.1f}%')}\n"
            )
            
            if user_analytics['total_pdf_reports']:
                report += f"  ‚Ä¢ PDF –æ—Ç—á–µ—Ç–æ–≤: {esc(user_analytics['total_pdf_reports'])}\n"
            
            if user_analytics['total_cashback_calculated']:
                cashback_calc = user_analytics['total_cashback_calculated']
                report += f"  ‚Ä¢ –ö–µ—à–±—ç–∫ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω: {esc(f'{cashback_calc:.0f}')} ‚ÇΩ\n"

        # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∏
        if recurring_payments_processed > 0:
            report += f"\nüîÑ \*–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∏:\* {esc(recurring_payments_processed)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ\n"

        # –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
        report += f"\n‚ö° \*–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:\* {esc(system_status)}\n"

        # –û—à–∏–±–∫–∏
        if user_analytics['total_errors']:
            report += f"\n‚ö†Ô∏è \*–û—à–∏–±–∫–∏:\* {esc(user_analytics['total_errors'])} –∑–∞ –¥–µ–Ω—å\n"

        report += f"\n‚è∞ –û—Ç—á–µ—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω: {esc(datetime.now().strftime('%H:%M'))}"

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        loop.run_until_complete(send_admin_alert(report, disable_notification=True))

        loop.close()

        logger.info(f"–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç –∑–∞ {yesterday} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}", exc_info=True)


@shared_task
def system_health_check():
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫"""
    try:
        from expenses.models import SystemHealthCheck, AIServiceMetrics
        from django.db import connection
        from django.core.cache import cache
        from django.utils import timezone
        from django.conf import settings
        import redis
        import requests
        import psutil
        import os
        from datetime import timedelta
        
        logger.info("–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã")
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        check_start = timezone.now()
        issues = []
        
        # =====================================
        # 1. –ë–ê–ó–ê –î–ê–ù–ù–´–•
        # =====================================
        database_status = False
        database_response_time = None
        try:
            db_start = timezone.now()
            with connection.cursor() as cursor:
                cursor.execute("SELECT COUNT(*) FROM users_profile")
                result = cursor.fetchone()
            database_response_time = (timezone.now() - db_start).total_seconds()
            database_status = True
            logger.info(f"Database check: OK ({database_response_time:.3f}s)")
        except Exception as e:
            logger.error(f"Database check failed: {e}")
            issues.append(f"Database connection failed: {str(e)[:100]}")
        
        # =====================================
        # 2. REDIS
        # =====================================
        redis_status = False
        redis_response_time = None
        redis_memory_usage = None
        try:
            redis_start = timezone.now()
            r = redis.Redis(
                host=getattr(settings, 'REDIS_HOST', 'localhost'),
                port=int(getattr(settings, 'REDIS_PORT', 6379)),
                db=0,
                socket_connect_timeout=5
            )
            r.ping()
            redis_response_time = (timezone.now() - redis_start).total_seconds()
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏
            info = r.info('memory')
            redis_memory_usage = info.get('used_memory', 0)
            
            redis_status = True
            logger.info(f"Redis check: OK ({redis_response_time:.3f}s, {redis_memory_usage//1024//1024}MB)")
        except Exception as e:
            logger.error(f"Redis check failed: {e}")
            issues.append(f"Redis connection failed: {str(e)[:100]}")
        
        # =====================================
        # 3. TELEGRAM API
        # =====================================
        telegram_api_status = False
        telegram_api_response_time = None
        try:
            telegram_start = timezone.now()
            bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') 
            if bot_token:
                response = requests.get(
                    f"https://api.telegram.org/bot{bot_token}/getMe",
                    timeout=10
                )
                if response.status_code == 200:
                    telegram_api_response_time = (timezone.now() - telegram_start).total_seconds()
                    telegram_api_status = True
                    logger.info(f"Telegram API check: OK ({telegram_api_response_time:.3f}s)")
                else:
                    issues.append(f"Telegram API returned status {response.status_code}")
            else:
                issues.append("Telegram bot token not configured")
        except Exception as e:
            logger.error(f"Telegram API check failed: {e}")
            issues.append(f"Telegram API check failed: {str(e)[:100]}")
        
        # =====================================
        # 4. OPENAI API
        # =====================================
        openai_api_status = False
        openai_api_response_time = None
        try:
            openai_start = timezone.now()
            openai_key = os.getenv('OPENAI_API_KEY')
            if openai_key:
                response = requests.get(
                    "https://api.openai.com/v1/models",
                    headers={"Authorization": f"Bearer {openai_key}"},
                    timeout=10
                )
                if response.status_code == 200:
                    openai_api_response_time = (timezone.now() - openai_start).total_seconds()
                    openai_api_status = True
                    logger.info(f"OpenAI API check: OK ({openai_api_response_time:.3f}s)")
                else:
                    issues.append(f"OpenAI API returned status {response.status_code}")
            else:
                logger.info("OpenAI API key not configured - skipping check")
        except Exception as e:
            logger.error(f"OpenAI API check failed: {e}")
            issues.append(f"OpenAI API check failed: {str(e)[:100]}")
        
        # =====================================
        # 5. GOOGLE AI API
        # =====================================
        google_ai_api_status = False
        google_ai_api_response_time = None
        try:
            google_start = timezone.now()
            google_key = os.getenv('GOOGLE_AI_KEY')
            if google_key:
                # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API
                response = requests.get(
                    f"https://generativelanguage.googleapis.com/v1beta/models?key={google_key}",
                    timeout=10
                )
                if response.status_code == 200:
                    google_ai_api_response_time = (timezone.now() - google_start).total_seconds()
                    google_ai_api_status = True
                    logger.info(f"Google AI API check: OK ({google_ai_api_response_time:.3f}s)")
                else:
                    issues.append(f"Google AI API returned status {response.status_code}")
            else:
                logger.info("Google AI API key not configured - skipping check")
        except Exception as e:
            logger.error(f"Google AI API check failed: {e}")
            issues.append(f"Google AI API check failed: {str(e)[:100]}")
        
        # =====================================
        # 6. CELERY
        # =====================================
        celery_status = False
        celery_workers_count = None
        celery_queue_size = None
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º celery app
            from expense_bot.celery import app
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–æ—Ä–∫–µ—Ä–∞—Ö
            inspect = app.control.inspect()
            stats = inspect.stats()
            
            if stats:
                celery_workers_count = len(stats)
                celery_status = True
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–µ–π
                active_queues = inspect.active_queues()
                queue_lengths = {}
                for worker, queues in (active_queues or {}).items():
                    for queue in queues:
                        queue_name = queue.get('name', 'default')
                        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –æ—á–µ—Ä–µ–¥–∏ –∏–∑ Redis
                        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞ –µ—Å–ª–∏ –≤–æ—Ä–∫–µ—Ä—ã –∞–∫—Ç–∏–≤–Ω—ã
                        queue_lengths[queue_name] = 0
                
                celery_queue_size = sum(queue_lengths.values())
                logger.info(f"Celery check: OK ({celery_workers_count} workers)")
            else:
                issues.append("No active Celery workers found")
        except Exception as e:
            logger.error(f"Celery check failed: {e}")
            issues.append(f"Celery check failed: {str(e)[:100]}")
        
        # =====================================
        # 7. –°–ò–°–¢–ï–ú–ù–´–ï –ú–ï–¢–†–ò–ö–ò
        # =====================================
        disk_free_gb = None
        memory_usage_percent = None
        cpu_usage_percent = None
        try:
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–∞
            disk_usage = psutil.disk_usage('/')
            disk_free_gb = disk_usage.free / (1024**3)  # –í –≥–∏–≥–∞–±–∞–π—Ç–∞—Ö
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
            memory = psutil.virtual_memory()
            memory_usage_percent = memory.percent
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU (—Å—Ä–µ–¥–Ω–µ–µ –∑–∞ 1 —Å–µ–∫—É–Ω–¥—É)
            cpu_usage_percent = psutil.cpu_percent(interval=1)
            
            logger.info(f"System metrics: {disk_free_gb:.1f}GB free, {memory_usage_percent:.1f}% RAM, {cpu_usage_percent:.1f}% CPU")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            if disk_free_gb < 1.0:  # –ú–µ–Ω—å—à–µ 1 –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
                issues.append(f"Low disk space: {disk_free_gb:.1f}GB free")
            
            if memory_usage_percent > 90:
                issues.append(f"High memory usage: {memory_usage_percent:.1f}%")
            
            if cpu_usage_percent > 80:
                issues.append(f"High CPU usage: {cpu_usage_percent:.1f}%")
                
        except Exception as e:
            logger.error(f"System metrics collection failed: {e}")
            issues.append(f"System metrics failed: {str(e)[:100]}")
        
        # =====================================
        # 8. –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –û–ë–©–ï–ì–û –°–¢–ê–¢–£–°–ê
        # =====================================
        critical_components = [database_status, redis_status]
        important_components = [telegram_api_status, celery_status]
        
        if all(critical_components):
            if all(important_components):
                overall_status = 'healthy'
            else:
                overall_status = 'degraded'
        else:
            overall_status = 'unhealthy'
        
        # =====================================
        # 9. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
        # =====================================
        health_check = SystemHealthCheck.objects.create(
            timestamp=check_start,
            database_status=database_status,
            database_response_time=database_response_time,
            redis_status=redis_status,
            redis_response_time=redis_response_time,
            redis_memory_usage=redis_memory_usage,
            telegram_api_status=telegram_api_status,
            telegram_api_response_time=telegram_api_response_time,
            openai_api_status=openai_api_status,
            openai_api_response_time=openai_api_response_time,
            google_ai_api_status=google_ai_api_status,
            google_ai_api_response_time=google_ai_api_response_time,
            celery_status=celery_status,
            celery_workers_count=celery_workers_count,
            celery_queue_size=celery_queue_size,
            disk_free_gb=disk_free_gb,
            memory_usage_percent=memory_usage_percent,
            cpu_usage_percent=cpu_usage_percent,
            overall_status=overall_status,
            issues=issues
        )
        
        # =====================================
        # 10. –û–¢–ü–†–ê–í–ö–ê –ê–õ–ï–†–¢–û–í –ï–°–õ–ò –ù–ï–û–ë–•–û–î–ò–ú–û
        # =====================================
        if overall_status in ['unhealthy', 'degraded'] or issues:
            try:
                from bot.services.admin_notifier import send_admin_alert, escape_markdown_v2
                
                status_emoji = {'healthy': '‚úÖ', 'degraded': '‚ö†Ô∏è', 'unhealthy': 'üö®'}
                
                alert_message = (
                    f"{status_emoji.get(overall_status, '‚ùì')} *–°–∏—Å—Ç–µ–º–Ω—ã–π –∞–ª–µ—Ä—Ç*\n\n"
                    f"–°—Ç–∞—Ç—É—Å: {escape_markdown_v2(overall_status.title())}\n"
                    f"–í—Ä–µ–º—è: {escape_markdown_v2(check_start.strftime('%H:%M:%S'))}\n\n"
                )
                
                if issues:
                    alert_message += "*–ü—Ä–æ–±–ª–µ–º—ã:*\n"
                    for issue in issues[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º
                        alert_message += f"‚Ä¢ {escape_markdown_v2(issue)}\n"
                    
                    if len(issues) > 5:
                        alert_message += f"‚Ä¢ ... –∏ –µ—â–µ {len(issues) - 5} –ø—Ä–æ–±–ª–µ–º\n"
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–ª–µ—Ä—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(send_admin_alert(alert_message))
                loop.close()
                
                logger.warning(f"System health alert sent: {overall_status} with {len(issues)} issues")
            
            except Exception as e:
                logger.error(f"Failed to send health alert: {e}")
        
        # =====================================
        # 11. –û–ß–ò–°–¢–ö–ê –°–¢–ê–†–´–• –ó–ê–ü–ò–°–ï–ô
        # =====================================
        try:
            # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
            old_threshold = timezone.now() - timedelta(days=30)
            deleted_count, _ = SystemHealthCheck.objects.filter(
                timestamp__lt=old_threshold
            ).delete()
            
            if deleted_count > 0:
                logger.info(f"Deleted {deleted_count} old health check records")
        
        except Exception as e:
            logger.error(f"Failed to cleanup old health checks: {e}")
        
        total_time = (timezone.now() - check_start).total_seconds()
        logger.info(f"System health check completed in {total_time:.2f}s: {overall_status}")
        
        return {
            'status': overall_status,
            'timestamp': check_start.isoformat(),
            'total_time': total_time,
            'issues_count': len(issues)
        }
        
    except Exception as e:
        logger.error(f"System health check task failed: {e}", exc_info=True)
        return {'status': 'error', 'error': str(e)}


@shared_task
def collect_daily_analytics():
    """–°–±–æ—Ä –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞ –¥–µ–Ω—å (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ –¥–Ω—è)"""
    try:
        from expenses.models import (
            Profile, Expense, Income, UserAnalytics, 
            AIServiceMetrics, Subscription, AffiliateCommission
        )
        from django.utils import timezone
        from django.db.models import Count, Sum, Avg, Q
        from datetime import timedelta
        import json

        logger.info("–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")
        
        # –í—á–µ—Ä–∞—à–Ω—è—è –¥–∞—Ç–∞ (–¥–∞–Ω–Ω—ã–µ –∑–∞ –∫–æ—Ç–æ—Ä—É—é —Å–æ–±–∏—Ä–∞–µ–º)
        target_date = (timezone.now() - timedelta(days=1)).date()
        target_start = timezone.make_aware(datetime.combine(target_date, time.min))
        target_end = timezone.make_aware(datetime.combine(target_date, time.max))
        
        processed_profiles = 0
        created_analytics = 0
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –∞–∫—Ç–∏–≤–Ω—ã –≤—á–µ—Ä–∞
        # (–¥–æ–±–∞–≤–ª—è–ª–∏ —Ä–∞—Å—Ö–æ–¥—ã, –¥–æ—Ö–æ–¥—ã, –∏–ª–∏ –∏–º–µ–ª–∏ –¥—Ä—É–≥—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å)
        active_profiles = Profile.objects.filter(
            Q(expenses__created_at__gte=target_start, expenses__created_at__lte=target_end) |
            Q(incomes__created_at__gte=target_start, incomes__created_at__lte=target_end) |
            Q(subscriptions__created_at__gte=target_start, subscriptions__created_at__lte=target_end)
        ).distinct()
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {active_profiles.count()} –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∑–∞ {target_date}")
        
        for profile in active_profiles:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ –∑–∞–ø–∏—Å–∏ –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å
                existing_analytics = UserAnalytics.objects.filter(
                    profile=profile,
                    date=target_date
                ).first()
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–∞—Å—Ö–æ–¥–∞–º
                expenses = Expense.objects.filter(
                    profile=profile,
                    created_at__gte=target_start,
                    created_at__lte=target_end
                )
                
                expenses_stats = expenses.aggregate(
                    count=Count('id'),
                    ai_categorized_count=Count('id', filter=Q(ai_categorized=True)),
                    manual_categorized_count=Count('id', filter=Q(ai_categorized=False)),
                )
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–æ—Ö–æ–¥–∞–º
                incomes = Income.objects.filter(
                    profile=profile,
                    created_at__gte=target_start,
                    created_at__lte=target_end
                )
                
                incomes_count = incomes.count()
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (—Ç–æ–ø-5 –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö)
                categories_used = {}
                for expense in expenses:
                    if expense.category:
                        cat_id = str(expense.category.id)
                        categories_used[cat_id] = categories_used.get(cat_id, 0) + 1
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ AI —Å–µ—Ä–≤–∏—Å–∞–º (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ - –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É AI –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–π)
                ai_categorizations = expenses_stats['ai_categorized_count'] or 0
                manual_categorizations = expenses_stats['manual_categorized_count'] or 0
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–µ—à–±—ç–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å –ª–æ–≥–∏–∫–∞)
                cashback_calculated = 0  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—á–µ—Ç –∫–µ—à–±—ç–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                cashback_transactions = 0
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ (–ø–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞, –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –ª–æ–≥–∞–º–∏)
                errors_encountered = 0
                error_types = {}
                
                # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏ (–∑–∞–≥–ª—É—à–∫–∞)
                total_session_time = 0
                peak_hour = None
                
                # PDF –æ—Ç—á–µ—Ç—ã (–∑–∞–≥–ª—É—à–∫–∞ - –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –ª–æ–≥–∏–∫–æ–π –æ—Ç—á–µ—Ç–æ–≤)
                pdf_reports_generated = 0
                
                # Recurring payments processed (–¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
                recurring_payments_processed = 0
                
                # Budget checks (–∑–∞–≥–ª—É—à–∫–∞)
                budget_checks = 0
                
                # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º/—Ñ–æ—Ç–æ (–∑–∞–≥–ª—É—à–∫–∞)
                messages_sent = expenses_stats['count'] or 0  # –ü—Ä–∏–º–µ—Ä–Ω–æ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ä–∞—Å—Ö–æ–¥–æ–≤
                voice_messages = 0  # –ó–∞–≥–ª—É—à–∫–∞
                photos_sent = 0     # –ó–∞–≥–ª—É—à–∫–∞
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–º–∞–Ω–¥—ã (–∑–∞–≥–ª—É—à–∫–∞)
                commands_used = {}
                if expenses_stats['count']:
                    commands_used['expense_add'] = expenses_stats['count']
                if incomes_count:
                    commands_used['income_add'] = incomes_count
                
                # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                if existing_analytics:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å
                    existing_analytics.messages_sent = messages_sent
                    existing_analytics.voice_messages = voice_messages
                    existing_analytics.photos_sent = photos_sent
                    existing_analytics.commands_used = commands_used
                    existing_analytics.expenses_added = expenses_stats['count'] or 0
                    existing_analytics.incomes_added = incomes_count
                    existing_analytics.categories_used = categories_used
                    existing_analytics.ai_categorizations = ai_categorizations
                    existing_analytics.manual_categorizations = manual_categorizations
                    existing_analytics.cashback_calculated = cashback_calculated
                    existing_analytics.cashback_transactions = cashback_transactions
                    existing_analytics.errors_encountered = errors_encountered
                    existing_analytics.error_types = error_types
                    existing_analytics.total_session_time = total_session_time
                    existing_analytics.peak_hour = peak_hour
                    existing_analytics.pdf_reports_generated = pdf_reports_generated
                    existing_analytics.recurring_payments_processed = recurring_payments_processed
                    existing_analytics.budget_checks = budget_checks
                    existing_analytics.save()
                    
                    logger.info(f"Updated analytics for user {profile.telegram_id} for {target_date}")
                else:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                    UserAnalytics.objects.create(
                        profile=profile,
                        date=target_date,
                        messages_sent=messages_sent,
                        voice_messages=voice_messages,
                        photos_sent=photos_sent,
                        commands_used=commands_used,
                        expenses_added=expenses_stats['count'] or 0,
                        incomes_added=incomes_count,
                        categories_used=categories_used,
                        ai_categorizations=ai_categorizations,
                        manual_categorizations=manual_categorizations,
                        cashback_calculated=cashback_calculated,
                        cashback_transactions=cashback_transactions,
                        errors_encountered=errors_encountered,
                        error_types=error_types,
                        total_session_time=total_session_time,
                        peak_hour=peak_hour,
                        pdf_reports_generated=pdf_reports_generated,
                        recurring_payments_processed=recurring_payments_processed,
                        budget_checks=budget_checks
                    )
                    created_analytics += 1
                    logger.debug(f"Created analytics for user {profile.telegram_id} for {target_date}")
                
                processed_profiles += 1
                
            except Exception as e:
                logger.error(f"Error processing analytics for user {profile.telegram_id}: {e}")
                continue
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (—Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π)
        try:
            old_threshold = timezone.now() - timedelta(days=90)
            deleted_count, _ = UserAnalytics.objects.filter(
                date__lt=old_threshold.date()
            ).delete()
            
            if deleted_count > 0:
                logger.info(f"Deleted {deleted_count} old analytics records")
        
        except Exception as e:
            logger.error(f"Failed to cleanup old analytics: {e}")
        
        logger.info(f"Daily analytics collection completed: {processed_profiles} users processed, {created_analytics} new records created")
        
        return {
            'date': target_date.isoformat(),
            'processed_profiles': processed_profiles,
            'created_analytics': created_analytics,
            'updated_analytics': processed_profiles - created_analytics
        }
    
    except Exception as e:
        logger.error(f"Daily analytics collection failed: {e}", exc_info=True)
        return {'error': str(e)}


@shared_task
def process_recurring_payments():
    """Process recurring payments for today at 12:00"""
    try:
        from bot.services.recurring import process_recurring_payments_for_today
        from bot.utils.expense_messages import format_expense_added_message
        from aiogram import Bot
        from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup
        # Use main bot token for user-facing notifications
        bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') or os.getenv('MONITORING_BOT_TOKEN')
        bot = Bot(token=bot_token)
        
        # Run async function in sync context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Process recurring payments
        processed_count, processed_payments = loop.run_until_complete(
            process_recurring_payments_for_today()
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –æ —Å–ø–∏—Å–∞–Ω–Ω—ã—Ö –µ–∂–µ–º–µ—Å—è—á–Ω—ã—Ö –ø–ª–∞—Ç–µ–∂–∞—Ö
        for payment_info in processed_payments:
            try:
                user_id = payment_info['user_id']
                expense = payment_info['expense']
                payment = payment_info['payment']
                
                # –ü–æ–ª—É—á–∞–µ–º —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è
                from expenses.models import Profile
                profile = Profile.objects.filter(telegram_id=user_id).first()
                user_lang = profile.language_code if profile else 'ru'
                
                # –î–ª—è –µ–∂–µ–º–µ—Å—è—á–Ω—ã—Ö –ø–ª–∞—Ç–µ–∂–µ–π –Ω–µ —Å—á–∏—Ç–∞–µ–º –∫–µ—à–±—ç–∫
                cashback_text = ""
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
                text = loop.run_until_complete(
                    format_expense_added_message(
                        expense=expense,
                        category=expense.category,
                        cashback_text=cashback_text,
                        is_recurring=True,  # –§–ª–∞–≥ –¥–ª—è –µ–∂–µ–º–µ—Å—è—á–Ω–æ–≥–æ –ø–ª–∞—Ç–µ–∂–∞
                        lang=user_lang
                    )
                )
                
                # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                keyboard = InlineKeyboardMarkup(inline_keyboard=[
                    [
                        InlineKeyboardButton(text="‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å", callback_data=f"edit_expense_{expense.id}"),
                        InlineKeyboardButton(text="üóë –£–¥–∞–ª–∏—Ç—å", callback_data=f"delete_expense_{expense.id}")
                    ]
                ])
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
                loop.run_until_complete(
                    bot.send_message(
                        chat_id=user_id,
                        text=text,
                        reply_markup=keyboard,
                        parse_mode="HTML"
                    )
                )
                
                logger.info(f"Sent notification to user {user_id} about recurring payment")
                
            except Exception as e:
                logger.error(f"Error sending notification to user {payment_info['user_id']}: {e}")
        
        loop.close()
        
        logger.info(f"Processed {processed_count} recurring payments")
        
    except Exception as e:
        logger.error(f"Error in process_recurring_payments task: {e}")


@shared_task
def update_keywords_weights(expense_id: int, old_category_id: int, new_category_id: int):
    """
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.
    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–µ –ø–æ—Å–ª–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
    """
    try:
        from expenses.models import Expense, ExpenseCategory, CategoryKeyword
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å spellchecker, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏
        try:
            from bot.utils.spellchecker import check_and_correct_text
        except ImportError:
            def check_and_correct_text(text):
                return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç—ã
        expense = Expense.objects.get(id=expense_id)
        new_category = ExpenseCategory.objects.get(id=new_category_id)
        old_category = ExpenseCategory.objects.get(id=old_category_id) if old_category_id else None
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ –æ—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
        words = extract_words_from_description(expense.description)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–æ–ø–∏—Å–∞–Ω–∏–µ
        corrected_words = []
        for word in words:
            corrected = check_and_correct_text(word)
            if corrected and len(corrected) >= 3:  # –ú–∏–Ω–∏–º—É–º 3 –±—É–∫–≤—ã
                corrected_words.append(corrected.lower())
        
        words = corrected_words
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ù–û–í–û–ô –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—Å–ø—Ä–∞–≤–∏–ª)
        for word in words:
            keyword, created = CategoryKeyword.objects.get_or_create(
                category=new_category,
                keyword=word,
                defaults={'normalized_weight': 1.0, 'usage_count': 0}
            )
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π
            keyword.usage_count += 1
            keyword.save()
            
            logger.info(f"Updated keyword '{word}' for category '{new_category.name}' (user {expense.profile.telegram_id})")
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏—Ö —Å–ª–æ–≤
        recalculate_normalized_weights(expense.profile.id, words)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç 50 —Å–ª–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        check_category_keywords_limit(new_category)
        if old_category:
            check_category_keywords_limit(old_category)
        
        logger.info(f"Successfully updated keywords weights for expense {expense_id}")
        
    except Exception as e:
        logger.error(f"Error in update_keywords_weights task: {e}")


def extract_words_from_description(description: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è —Ä–∞—Å—Ö–æ–¥–∞"""
    # –£–¥–∞–ª—è–µ–º —á–∏—Å–ª–∞, –≤–∞–ª—é—Ç—É, –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    text = re.sub(r'\d+', '', description)
    text = re.sub(r'[‚ÇΩ$‚Ç¨¬£¬•—Ä\.,"\'!?;:\-\(\)]', ' ', text)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    words = text.lower().split()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    stop_words = {
        '–∏', '–≤', '–Ω–∞', '—Å', '–∑–∞', '–ø–æ', '–¥–ª—è', '–æ—Ç', '–¥–æ', '–∏–∑',
        '–∏–ª–∏', '–Ω–æ', '–∞', '–∫', '—É', '–æ', '–æ–±', '–ø–æ–¥', '–Ω–∞–¥',
        '–∫—É–ø–∏–ª', '–∫—É–ø–∏–ª–∞', '–∫—É–ø–∏–ª–∏', '–≤–∑—è–ª', '–≤–∑—è–ª–∞', '–≤–∑—è–ª–∏',
        '–ø–æ—Ç—Ä–∞—Ç–∏–ª', '–ø–æ—Ç—Ä–∞—Ç–∏–ª–∞', '–ø–æ—Ç—Ä–∞—Ç–∏–ª–∏', '–æ–ø–ª–∞—Ç–∏–ª', '–æ–ø–ª–∞—Ç–∏–ª–∞',
        '—Ä—É–±–ª—å', '—Ä—É–±–ª—è', '—Ä—É–±–ª–µ–π', '—Ä—É–±', '—Ä', '—Ç—ã—Å', '—Ç—ã—Å—è—á'
    }
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–æ–≤–∞
    filtered_words = []
    for word in words:
        word = word.strip()
        if word and len(word) >= 3 and word not in stop_words:
            filtered_words.append(word)
    
    return filtered_words


def recalculate_normalized_weights(profile_id: int, words: List[str]):
    """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è —Å–ª–æ–≤, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö"""
    from expenses.models import CategoryKeyword, Profile
    
    try:
        profile = Profile.objects.get(id=profile_id)
        
        for word in words:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è —Å–ª–æ–≤–∞ —É –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            keywords = CategoryKeyword.objects.filter(
                category__profile=profile,
                keyword=word
            )
            
            if keywords.count() > 1:
                # –°–ª–æ–≤–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
                total_usage = sum(kw.usage_count for kw in keywords)
                
                if total_usage > 0:
                    for kw in keywords:
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å –æ—Ç 0 –¥–æ 1 –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                        kw.normalized_weight = kw.usage_count / total_usage
                        kw.save()
                        
                    logger.info(f"Recalculated weights for word '{word}' across {keywords.count()} categories")
    
    except Exception as e:
        logger.error(f"Error recalculating weights: {e}")


def check_category_keywords_limit(category):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–º–∞–∫—Å–∏–º—É–º 50)"""
    from expenses.models import CategoryKeyword
    
    try:
        keywords = CategoryKeyword.objects.filter(category=category)
        
        if keywords.count() > 50:
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ø-50 –ø–æ usage_count
            keywords_list = list(keywords)
            keywords_list.sort(key=lambda k: k.usage_count, reverse=True)
            
            # –£–¥–∞–ª—è–µ–º —Å–ª–æ–≤–∞ —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
            keywords_to_delete = keywords_list[50:]
            for kw in keywords_to_delete:
                logger.info(f"Deleting keyword '{kw.keyword}' from category '{category.name}' (low usage)")
                kw.delete()
            
            logger.info(f"Limited keywords for category '{category.name}' to 50 items")
    
    except Exception as e:
        logger.error(f"Error checking category keywords limit: {e}")


# Backward compatible entry-point that now calls the new task implementation
@shared_task
def process_held_affiliate_commissions():
    from expenses.tasks import process_affiliate_commissions

    logger.warning(
        "process_held_affiliate_commissions is deprecated; routing to expenses.tasks.process_affiliate_commissions"
    )
    return process_affiliate_commissions()


@shared_task
def update_top5_keyboards():
    """–ï–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 05:00 MSK: –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –¢–æ–ø‚Äë5 –∏ –æ–±–Ω–æ–≤–∏—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."""
    try:
        from expenses.models import Profile, Top5Snapshot, Top5Pin
        from bot.services.top5 import (
            calculate_top5_sync, save_snapshot, build_top5_keyboard, get_profiles_with_activity
        )
        from datetime import date
        from calendar import monthrange

        # –ë–æ—Ç –¥–ª—è –≤—ã–∑–æ–≤–∞ editMessageReplyMarkup
        bot_token = os.getenv('BOT_TOKEN') or os.getenv('TELEGRAM_BOT_TOKEN') or os.getenv('MONITORING_BOT_TOKEN')
        bot = Bot(token=bot_token)

        # –û–∫–Ω–æ: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ (rolling)
        today = date.today()
        from datetime import timedelta
        window_end = today
        window_start = today - timedelta(days=89)

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é
        profiles = asyncio.get_event_loop().run_until_complete(get_profiles_with_activity(window_start, window_end))

        updated = 0
        for profile in profiles:
            try:
                items, digest = asyncio.get_event_loop().run_until_complete(calculate_top5_sync(profile, window_start, window_end))
                snap = Top5Snapshot.objects.filter(profile=profile).first()
                if not snap or snap.hash != digest or snap.window_start != window_start or snap.window_end != window_end:
                    asyncio.get_event_loop().run_until_complete(
                        save_snapshot(profile, window_start, window_end, items, digest)
                    )
                # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –∑–Ω–∞–µ–º ids
                pin = Top5Pin.objects.filter(profile=profile).first()
                if pin:
                    kb: InlineKeyboardMarkup = build_top5_keyboard(items)
                    asyncio.get_event_loop().run_until_complete(
                        bot.edit_message_reply_markup(chat_id=pin.chat_id, message_id=pin.message_id, reply_markup=kb)
                    )
                    updated += 1
            except Exception as user_err:
                logger.error(f"Top-5 update error for user {profile.telegram_id}: {user_err}")
                continue
        logger.info(f"Top-5 updated for {updated} pinned messages (profiles processed: {len(profiles)})")
    except Exception as e:
        logger.error(f"Error in update_top5_keyboards: {e}")
