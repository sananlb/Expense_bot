"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –≤–æ–ø—Ä–æ—Å–æ–≤ –∫ –±–æ—Ç—É (–±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ Django setup)
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏–∫—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–Ω—Ç–µ–Ω—Ç–æ–≤
"""
import sys
import re
from datetime import datetime
from typing import Dict, List, Tuple


# –ö–æ–ø–∏—è –ª–æ–≥–∏–∫–∏ –∏–∑ expense_intent.py
def is_show_expenses_request(text: str) -> Tuple[bool, float]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–æ–º –ø–æ–∫–∞–∑–∞ —Ç—Ä–∞—Ç"""
    text_lower = text.lower().strip()

    # –ê–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω—ã - —ç—Ç–æ –ù–ï –∑–∞–ø—Ä–æ—Å –ø–æ–∫–∞–∑–∞
    analytical_patterns = [
        '–∫–∞–∫–∞—è —Å–∞–º–∞—è', '–∫–∞–∫–æ–π —Å–∞–º—ã–π', '–∫–∞–∫–∏–µ —Å–∞–º—ã–µ',
        '—Å–∞–º–∞—è –±–æ–ª—å—à–∞—è', '—Å–∞–º—ã–π –±–æ–ª—å—à–æ–π', '—Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ',
        '–Ω–∞ —á—Ç–æ –±–æ–ª—å—à–µ', '–Ω–∞ —á—Ç–æ –º–µ–Ω—å—à–µ',
        '—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑', '–∫–∞–∫ —á–∞—Å—Ç–æ',
        '–≤ –∫–∞–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏',
        '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–¥–ª—è —á–µ–≥–æ',
        '–æ–±—ä—è—Å–Ω–∏', '—Ä–∞—Å—Å–∫–∞–∂–∏', '–æ–ø–∏—à–∏',
        '–∞–Ω–∞–ª–∏–∑', '–∞–Ω–∞–ª–∏—Ç–∏–∫–∞', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞',
        '—Å—Ä–∞–≤–Ω–∏', '—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ',
        '—Ç—Ä–µ–Ω–¥', '–¥–∏–Ω–∞–º–∏–∫–∞', '–∏–∑–º–µ–Ω–µ–Ω–∏–µ',
        '–ø—Ä–æ–≥–Ω–æ–∑', '–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ',
        '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏', '—Å–æ–≤–µ—Ç—ã', '–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è',
        '–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è', '—ç–∫–æ–Ω–æ–º–∏—è', '—Å–æ–∫—Ä–∞—Ç–∏—Ç—å',
        '—Å—Ä–µ–¥–Ω'  # —Å—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞, —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫
    ]

    if any(pattern in text_lower for pattern in analytical_patterns):
        return False, 0.0

    # –ì–æ—Ç–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    show_expense_phrases = [
        '—Ç—Ä–∞—Ç—ã –∑–∞', '—Ä–∞—Å—Ö–æ–¥—ã –∑–∞', '—Ç—Ä–∞—Ç—ã –≤—á–µ—Ä–∞', '—Ç—Ä–∞—Ç—ã —Å–µ–≥–æ–¥–Ω—è',
        '–ø–æ–∫–∞–∂–∏ —Ç—Ä–∞—Ç—ã', '–ø–æ–∫–∞–∑–∞—Ç—å —Ç—Ä–∞—Ç—ã', '—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç—Ä–∞—Ç–∏–ª',
        '–º–æ–∏ —Ç—Ä–∞—Ç—ã', '–¥–Ω–µ–≤–Ω–∏–∫ —Ç—Ä–∞—Ç', '–∏—Å—Ç–æ—Ä–∏—è —Ç—Ä–∞—Ç'
    ]

    for phrase in show_expense_phrases:
        if phrase in text_lower:
            return True, 1.0

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    show_verbs = ['–ø–æ–∫–∞–∑–∞—Ç—å', '–ø–æ–∫–∞–∂–∏', '–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å', '–ø–æ—Å–º–æ—Ç—Ä–∏', '–≤—ã–≤–µ—Å—Ç–∏', '–≤—ã–≤–µ–¥–∏',
                  '–¥–∞–π', '—Å–∫–∞–∂–∏', '—Ä–∞—Å—Å–∫–∞–∂–∏', '—Å–∫–æ–ª—å–∫–æ', '–∫–∞–∫–∏–µ', '—á—Ç–æ', '–ø—Ä–æ–≤–µ—Ä–∏—Ç—å']

    time_markers = ['—Å–µ–≥–æ–¥–Ω—è', '–≤—á–µ—Ä–∞', '–ø–æ–∑–∞–≤—á–µ—Ä–∞', '–Ω–µ–¥–µ–ª—è', '–º–µ—Å—è—Ü', '–≥–æ–¥',
                    '—è–Ω–≤–∞—Ä', '—Ñ–µ–≤—Ä–∞–ª', '–º–∞—Ä—Ç', '–∞–ø—Ä–µ–ª', '–º–∞–π', '–∏—é–Ω', '–∏—é–ª', '–∞–≤–≥—É—Å—Ç',
                    '—Å–µ–Ω—Ç—è–±—Ä', '–æ–∫—Ç—è–±—Ä', '–Ω–æ—è–±—Ä', '–¥–µ–∫–∞–±—Ä']

    expense_words = ['—Ç—Ä–∞—Ç–∞', '—Ç—Ä–∞—Ç—ã', '—Ä–∞—Å—Ö–æ–¥', '—Ä–∞—Å—Ö–æ–¥—ã', '–ø–æ—Ç—Ä–∞—Ç–∏–ª', '–ø–æ—Ç—Ä–∞—Ç–∏–ª–∞',
                     '–∏–∑—Ä–∞—Å—Ö–æ–¥–æ–≤–∞–ª', 'expense', 'expenses', 'spent',
                     '–¥–Ω–µ–≤–Ω–∏–∫', '–∂—É—Ä–Ω–∞–ª', '–∏—Å—Ç–æ—Ä–∏—è']

    has_show_verb = any(verb in text_lower for verb in show_verbs)
    has_time_marker = any(marker in text_lower for marker in time_markers)
    has_expense_word = any(word in text_lower for word in expense_words)

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    if has_show_verb and has_expense_word:
        return True, 0.95
    if has_show_verb and has_time_marker:
        return True, 0.9
    if '—Å–∫–æ–ª—å–∫–æ' in text_lower and '–ø–æ—Ç—Ä–∞—Ç–∏–ª' in text_lower:
        return True, 0.85

    # –£–î–ê–õ–ï–ù–û: –§—Ä–∞–∑—ã —Ç–∏–ø–∞ "—Ç—Ä–∞—Ç—ã –≤ —Å–µ–Ω—Ç—è–±—Ä–µ" —Ç–µ–ø–µ—Ä—å –∏–¥—É—Ç –≤ expense parser –∫–∞–∫ –∑–∞–ø–∏—Å–∏

    return False, 0.0


# –ö–æ–ø–∏—è –ª–æ–≥–∏–∫–∏ –∏–∑ text_classifier.py (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
def classify_message(text: str) -> Tuple[str, float]:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ 'expense' (—Ç—Ä–∞—Ç–∞) –∏–ª–∏ 'chat'

    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞:
    1. –ï—Å–ª–∏ –µ—Å—Ç—å '?' ‚Üí chat
    2. –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞ (—á—Ç–æ, –∫–∞–∫, –≥–¥–µ...) ‚Üí chat
    3. –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ª–æ–≤–∞-–¥–µ–π—Å—Ç–≤–∏—è (–ø–æ–∫–∞–∂–∏, –Ω–∞–π–¥–∏, –≤—ã–≤–µ–¥–∏) ‚Üí chat
    4. –ò–Ω–∞—á–µ ‚Üí expense (—Ç—Ä–∞—Ç–∞)
    """
    text = text.strip()
    text_lower = text.lower()

    # –í–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
    question_words = ['—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–∫—Ç–æ', '–∫–∞–∫–æ–π', '–∫–∞–∫–∞—è', '–∫–∞–∫–∏–µ', '—Å–∫–æ–ª—å–∫–æ']

    # –°–ª–æ–≤–∞-–¥–µ–π—Å—Ç–≤–∏—è
    chat_action_words = [
        '–ø–æ–∫–∞–∂–∏', '–Ω–∞–π–¥–∏', '–≤—ã–≤–µ–¥–∏', '—Å—Ä–∞–≤–Ω–∏',
        '–ø–æ–∫–∞–∂', '–Ω–∞–π–¥', '–≤—ã–≤–µ–¥', '—Å—Ä–∞–≤–Ω'
    ]

    # 1. –ü–†–ò–û–†–ò–¢–ï–¢: –í–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∑–Ω–∞–∫ ‚Üí –≤—Å–µ–≥–¥–∞ —á–∞—Ç
    if text.endswith('?'):
        return 'chat', 1.0

    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ - –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ?
    words = text_lower.split()
    if words and words[0] in question_words:
        return 'chat', 0.95

    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤-–¥–µ–π—Å—Ç–≤–∏–π (–ø–æ–∫–∞–∂–∏, –Ω–∞–π–¥–∏, –≤—ã–≤–µ–¥–∏)
    for action_word in chat_action_words:
        if action_word in text_lower:
            return 'chat', 0.9

    # 4. –í–°–ï –û–°–¢–ê–õ–¨–ù–û–ï ‚Üí expense (—Ç—Ä–∞—Ç–∞)
    return 'expense', 0.8


# –ü—Ä–æ—Å—Ç–∞—è —ç–º—É–ª—è—Ü–∏—è FAQ matcher
def check_faq_match(text: str) -> Tuple[float, str]:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ FAQ (–±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ FAQ —Å–µ—Ä–≤–∏—Å–∞)"""
    text_norm = text.lower().strip().replace('—ë', '–µ')
    text_norm = re.sub(r'[^a-z–∞-—è0-9\s]', ' ', text_norm)
    text_norm = re.sub(r'\s+', ' ', text_norm).strip()

    # –≠–º—É–ª–∏—Ä—É–µ–º FAQ –≤–æ–ø—Ä–æ—Å—ã (–ø–æ—Å–ª–µ –Ω–∞—à–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    faq_questions = {
        '—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å': ('capabilities', 1.0),
        '–ø–æ–º–æ—â—å': ('capabilities', 1.0),
        '–∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º': ('capabilities', 0.95),
        '–∫–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å —Ç—Ä–∞—Ç—É': ('add_expense', 1.0),
        '–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–µ—à–±—ç–∫': ('cashback', 1.0),
        '–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫—ç—à–±—ç–∫': ('cashback', 1.0),
        '–∫–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ª–∏–º–∏—Ç': ('limits', 1.0),
        '—á—Ç–æ –¥–∞–µ—Ç –ø–æ–¥–ø–∏—Å–∫–∞': ('subscription', 1.0),
        '—á—Ç–æ –¥–∞—ë—Ç –ø–æ–¥–ø–∏—Å–∫–∞': ('subscription', 1.0),
        '–∫–∞–∫ —É–ø—Ä–∞–≤–ª—è—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏': ('categories_manage', 1.0),
        '–∫–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç—á–µ—Ç': ('view_reports', 1.0),
        '–∫–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç—á—ë—Ç': ('view_reports', 1.0),
        '–≥–¥–µ –Ω–∞–π—Ç–∏ –æ—Ç—á–µ—Ç—ã': ('view_reports', 0.95),
        '–≥–¥–µ –Ω–∞–π—Ç–∏ –æ—Ç—á—ë—Ç—ã': ('view_reports', 0.95),
        '–∫–∞–∫ —Å–∫–∞—á–∞—Ç—å excel': ('view_reports', 0.90),
        '–∫–∞–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å pdf': ('view_reports', 0.90),
    }

    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if text_norm in faq_questions:
        faq_id, confidence = faq_questions[text_norm]
        return confidence, faq_id

    # Fuzzy matching (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
    from difflib import SequenceMatcher
    best_ratio = 0.0
    best_id = None

    for faq_q, (faq_id, _) in faq_questions.items():
        ratio = SequenceMatcher(None, text_norm, faq_q).ratio()
        if ratio > best_ratio and ratio >= 0.72:
            best_ratio = ratio
            best_id = faq_id

    if best_ratio >= 0.72:
        return best_ratio, best_id

    return 0.0, None


# –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
TEST_QUESTIONS = {
    "FAQ - –û–±—â–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏": [
        "–ß—Ç–æ —Ç—ã —É–º–µ–µ—à—å?",
        "–ü–æ–º–æ—â—å",
        "–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º?",
    ],
    "FAQ - –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏": [
        "–ö–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å —Ç—Ä–∞—Ç—É?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–µ—à–±—ç–∫?",
        "–ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ª–∏–º–∏—Ç?",
        "–ß—Ç–æ –¥–∞–µ—Ç –ø–æ–¥–ø–∏—Å–∫–∞?",
        "–ö–∞–∫ —É–ø—Ä–∞–≤–ª—è—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏?",
    ],
    "FAQ - –û—Ç—á–µ—Ç—ã": [
        "–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç—á–µ—Ç?",
        "–ì–¥–µ –Ω–∞–π—Ç–∏ –æ—Ç—á–µ—Ç—ã?",
        "–ö–∞–∫ —Å–∫–∞—á–∞—Ç—å Excel?",
        "–ö–∞–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å PDF?",
    ],
    "–ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ (–∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã)": [
        "–ü–æ–∫–∞–∂–∏ —Ç—Ä–∞—Ç—ã",
        "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
        "–û—Ç—á–µ—Ç",
    ],
    "AI - –ó–∞–ø—Ä–æ—Å—ã —Å –ø–µ—Ä–∏–æ–¥–∞–º–∏": [
        "–ü–æ–∫–∞–∂–∏ —Ç—Ä–∞—Ç—ã –∑–∞ –Ω–æ—è–±—Ä—å",
        "–ü–æ–∫–∞–∂–∏ –≤—Å–µ —Ç—Ä–∞—Ç—ã –∑–∞ –æ–∫—Ç—è–±—Ä—å",
        "–¢—Ä–∞—Ç—ã –≤ —Å–µ–Ω—Ç—è–±—Ä–µ",
        "–°–∫–æ–ª—å–∫–æ —è –ø–æ—Ç—Ä–∞—Ç–∏–ª –≤ –Ω–æ—è–±—Ä–µ?",
        "–°–∫–æ–ª—å–∫–æ —è –ø–æ—Ç—Ä–∞—Ç–∏–ª —Å–µ–≥–æ–¥–Ω—è?",
        "–ü–æ–∫–∞–∂–∏ —Ç—Ä–∞—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é",
    ],
    "AI - –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã": [
        "–ù–∞ —á—Ç–æ —è –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ —Ç—Ä–∞—á—É?",
        "–ö–∞–∫–∞—è —Å–∞–º–∞—è –±–æ–ª—å—à–∞—è —Ç—Ä–∞—Ç–∞ –≤ –Ω–æ—è–±—Ä–µ?",
        "–°—Ä–∞–≤–Ω–∏ —Ç—Ä–∞—Ç—ã –≤ –æ–∫—Ç—è–±—Ä–µ –∏ –Ω–æ—è–±—Ä–µ",
        "–í –∫–∞–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ —Ä–∞—Å—Ö–æ–¥–æ–≤?",
        "–ö–∞–∫–∞—è —Ç—Ä–∞—Ç–∞ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —á–∞—â–µ –≤—Å–µ–≥–æ?",
        "–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ —Ç—Ä–∞—Ç –≤ –¥–µ–Ω—å",
    ],
    "AI - –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã": [
        "–°–∫–æ–ª—å–∫–æ —è –ø–æ—Ç—Ä–∞—Ç–∏–ª –Ω–∞ –∫–∞—Ñ–µ –≤ –Ω–æ—è–±—Ä–µ?",
        "–ü–æ–∫–∞–∂–∏ —Ç—Ä–∞—Ç—ã –±–æ–ª—å—à–µ 5000 —Ä—É–±–ª–µ–π",
        "–¢—Ä–∞—Ç—ã –≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ –∑–∞ –æ–∫—Ç—è–±—Ä—å",
    ],
}


def test_question(text: str) -> Dict:
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å"""
    result = {'text': text}

    # 1. FAQ –ø—Ä–æ–≤–µ—Ä–∫–∞
    faq_confidence, faq_id = check_faq_match(text)
    result['faq_confidence'] = faq_confidence
    result['faq_id'] = faq_id
    result['faq_matched'] = faq_confidence >= 0.60

    # 2. Show expenses intent
    is_show, show_confidence = is_show_expenses_request(text)
    result['show_intent'] = is_show
    result['show_confidence'] = show_confidence

    # 3. Text classifier
    msg_type, classify_confidence = classify_message(text)
    result['classifier_type'] = msg_type
    result['classifier_confidence'] = classify_confidence

    # 4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
    if faq_confidence >= 0.85:
        result['handler'] = 'FAQ (high confidence)'
        result['handler_type'] = 'FAQ'
    elif faq_confidence >= 0.60:
        result['handler'] = 'FAQ (medium confidence)'
        result['handler_type'] = 'FAQ'
    elif is_show and show_confidence >= 0.7:
        result['handler'] = 'AI (show expenses)'
        result['handler_type'] = 'AI'
    elif msg_type == 'chat':
        result['handler'] = 'AI (chat classifier)'
        result['handler_type'] = 'AI'
    else:
        result['handler'] = 'Expense Parser (default)'
        result['handler_type'] = 'EXPENSE'

    return result


def run_tests():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã"""
    print("=" * 80)
    print("üß™ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –í–û–ü–†–û–°–û–í –ö –ë–û–¢–£")
    print("=" * 80)
    print(f"–í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    all_results = []
    total_questions = sum(len(questions) for questions in TEST_QUESTIONS.values())
    current = 0

    for category, questions in TEST_QUESTIONS.items():
        print(f"\n{'=' * 80}")
        print(f"üìÇ {category}")
        print(f"{'=' * 80}\n")

        for question in questions:
            current += 1
            print(f"[{current}/{total_questions}] –¢–µ—Å—Ç–∏—Ä—É—é: \"{question}\"")

            result = test_question(question)
            all_results.append(result)

            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            handler_emoji = {
                'FAQ': 'üìã',
                'AI': 'ü§ñ',
                'EXPENSE': 'üí∏'
            }.get(result['handler_type'], '‚ùì')

            print(f"  {handler_emoji} –û–±—Ä–∞–±–æ—Ç—á–∏–∫: {result['handler']}")

            if result['faq_matched']:
                print(f"  üìã FAQ: {result['faq_id']} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['faq_confidence']:.2f})")

            if result['show_intent']:
                print(f"  üîç Show intent: {result['show_confidence']:.2f}")

            if result['classifier_type'] == 'chat':
                print(f"  üí¨ Classifier: {result['classifier_type']} ({result['classifier_confidence']:.2f})")

            print()

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 80)
    print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 80)

    faq_count = sum(1 for r in all_results if r['handler_type'] == 'FAQ')
    ai_count = sum(1 for r in all_results if r['handler_type'] == 'AI')
    expense_count = sum(1 for r in all_results if r['handler_type'] == 'EXPENSE')

    print(f"\nüìã FAQ –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç: {faq_count}/{total_questions} ({faq_count/total_questions*100:.1f}%)")
    print(f"ü§ñ AI –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç: {ai_count}/{total_questions} ({ai_count/total_questions*100:.1f}%)")
    print(f"üí∏ Expense Parser: {expense_count}/{total_questions} ({expense_count/total_questions*100:.1f}%)")

    # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–ª—É—á–∞–∏
    print("\n" + "=" * 80)
    print("‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ù–´–ï –°–õ–£–ß–ê–ò")
    print("=" * 80)

    problems = []

    # –ë–ª–æ–∫ 1-3: –î–æ–ª–∂–Ω—ã –∏–¥—Ç–∏ –≤ FAQ
    expected_faq = (
        TEST_QUESTIONS["FAQ - –û–±—â–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏"] +
        TEST_QUESTIONS["FAQ - –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"] +
        TEST_QUESTIONS["FAQ - –û—Ç—á–µ—Ç—ã"]
    )
    for question in expected_faq:
        result = next(r for r in all_results if r['text'] == question)
        if result['handler_type'] != 'FAQ':
            problems.append({
                'question': question,
                'expected': 'FAQ',
                'actual': result['handler_type'],
                'reason': result['handler']
            })

    # –ë–ª–æ–∫ 5-7: –î–æ–ª–∂–Ω—ã –∏–¥—Ç–∏ –≤ AI, –ö–†–û–ú–ï —Ñ—Ä–∞–∑ –±–µ–∑ –ø—Ä–∏–∑—ã–≤–∞ –∫ –¥–µ–π—Å—Ç–≤–∏—é
    # –ò—Å–∫–ª—é—á–µ–Ω–∏—è (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å EXPENSE):
    # - "–¢—Ä–∞—Ç—ã –≤ —Å–µ–Ω—Ç—è–±—Ä–µ" - –Ω–µ—Ç –≥–ª–∞–≥–æ–ª–∞ –¥–µ–π—Å—Ç–≤–∏—è
    # - "–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ —Ç—Ä–∞—Ç –≤ –¥–µ–Ω—å" - –Ω–µ—Ç –≥–ª–∞–≥–æ–ª–∞ –¥–µ–π—Å—Ç–≤–∏—è
    # - "–¢—Ä–∞—Ç—ã –≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ –∑–∞ –æ–∫—Ç—è–±—Ä—å" - –Ω–µ—Ç –≥–ª–∞–≥–æ–ª–∞ –¥–µ–π—Å—Ç–≤–∏—è
    exceptions_to_expense = [
        "–¢—Ä–∞—Ç—ã –≤ —Å–µ–Ω—Ç—è–±—Ä–µ",
        "–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ —Ç—Ä–∞—Ç –≤ –¥–µ–Ω—å",
        "–¢—Ä–∞—Ç—ã –≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ –∑–∞ –æ–∫—Ç—è–±—Ä—å"
    ]

    expected_ai = (
        TEST_QUESTIONS["AI - –ó–∞–ø—Ä–æ—Å—ã —Å –ø–µ—Ä–∏–æ–¥–∞–º–∏"] +
        TEST_QUESTIONS["AI - –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã"] +
        TEST_QUESTIONS["AI - –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã"]
    )
    for question in expected_ai:
        result = next(r for r in all_results if r['text'] == question)

        # –ï—Å–ª–∏ —ç—Ç–æ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–Ω–æ EXPENSE
        if question in exceptions_to_expense:
            if result['handler_type'] != 'EXPENSE':
                problems.append({
                    'question': question,
                    'expected': 'EXPENSE',
                    'actual': result['handler_type'],
                    'reason': result['handler']
                })
        # –ò–Ω–∞—á–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å AI
        elif result['handler_type'] == 'EXPENSE':
            problems.append({
                'question': question,
                'expected': 'AI',
                'actual': result['handler_type'],
                'reason': result['handler']
            })

    if problems:
        print(f"\n‚ùå –ù–∞–π–¥–µ–Ω–æ {len(problems)} –ø—Ä–æ–±–ª–µ–º:\n")
        for i, p in enumerate(problems, 1):
            print(f"{i}. \"{p['question']}\"")
            print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: {p['expected']}")
            print(f"   –ü–æ–ª—É—á–µ–Ω–æ: {p['actual']} ({p['reason']})")
            print()
    else:
        print("\n‚úÖ –ü—Ä–æ–±–ª–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ! –í—Å–µ –≤–æ–ø—Ä–æ—Å—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.")

    # –ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏
    print("\n" + "=" * 80)
    print("üîç –ì–†–ê–ù–ò–ß–ù–´–ï –°–õ–£–ß–ê–ò")
    print("=" * 80 + "\n")

    for question in TEST_QUESTIONS["–ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ (–∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã)"]:
        result = next(r for r in all_results if r['text'] == question)
        print(f"‚Ä¢ \"{question}\" ‚Üí {result['handler_type']} ({result['handler']})")

    print("\n" + "=" * 80)
    print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 80)

    return all_results, problems


if __name__ == "__main__":
    run_tests()
